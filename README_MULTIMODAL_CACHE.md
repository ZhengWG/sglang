# å¤šæ¨¡æ€Embeddingåˆ†æ‰¹ä¼ è¾“åŠŸèƒ½

## ğŸ¯ åŠŸèƒ½è¯´æ˜

æ”¯æŒå¤šæ¨¡æ€Embeddingæ•°æ®åˆ†æ‰¹ä¼ è¾“ï¼Œè§£å†³å®é™…æ•°æ®é•¿åº¦è¶…è¿‡é»˜è®¤bufferæ—¶çš„ä¼ è¾“é—®é¢˜ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### é…ç½®

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export SGLANG_MULTIMODAL_BLOCK_SIZE=128          # Blockå¤§å°
export SGLANG_DEFAULT_MULTIMODAL_BLOCKS=8        # Languageä¾§é»˜è®¤ç”³è¯·8ä¸ªblocks
export SGLANG_EMBEDDING_CACHE_BUFFER_SIZE=64     # Bufferæ€»æ•°é‡
```

### å¯åŠ¨

```bash
# Embeddingä¾§
python -m sglang.launch_server \
    --model-path /path/to/model \
    --disaggregation-mode encode \
    --disaggregation-bootstrap-port 8001

# Languageä¾§
python -m sglang.launch_server \
    --model-path /path/to/model \
    --disaggregation-mode language \
    --disaggregation-bootstrap-addr localhost:8001
```

---

## ğŸ“Š å·¥ä½œåŸç†

### æ ¸å¿ƒæœºåˆ¶

**é—®é¢˜**ï¼šLanguageä¾§ä¸çŸ¥é“å®é™…é•¿åº¦ â†’ åªèƒ½é¢„åˆ†é…é»˜è®¤buffer

**è§£å†³**ï¼šä¸¤é˜¶æ®µä¼ è¾“ + Resumeæœºåˆ¶

```
å®é™…é•¿åº¦2000 > é»˜è®¤1024 æ—¶ï¼š

ç¬¬1æ¬¡ä¼ è¾“ï¼šå‘é€1024 + aux_data[æ€»é•¿åº¦=2000]
         â†“
Language: è¯»å–æ€»é•¿åº¦ï¼Œåˆ¤æ–­éœ€è¦resume
         â†“
ç¬¬2æ¬¡ä¼ è¾“ï¼šå‘é€å‰©ä½™976 tokens
         â†“
æ‹¼æ¥å®Œæˆï¼š1024 + 976 = 2000 âœ“
```

### æ ¸å¿ƒç»„ä»¶

1. **ReqToMetadataBlockAllocator** - Block-basedåˆ†é…å™¨
   - Languageä¾§ï¼š`alloc_default()` åˆ†é…å›ºå®š8ä¸ªblocks
   - Embeddingä¾§ï¼š`alloc(num_tokens)` æŒ‰å®é™…é•¿åº¦åˆ†é…
   - ä¿è¯è¿ç»­åˆ†é…ï¼šblocks = [start, start+1, ..., start+num-1]

2. **MultimodalDataBuffers** - Bufferç®¡ç†
   - è¿ç»­å†…å­˜ï¼ŒæŒ‰blocké€»è¾‘ç®¡ç†
   - æ”¯æŒoffsetå’Œmax_tokenså‚æ•°

3. **Resumeæœºåˆ¶** - åˆ†æ‰¹ä¼ è¾“
   - `resume_transfer(allocation, sent_tokens)` - æ¢å¤ä¼ è¾“
   - `buffered_chunks` - ç¼“å­˜ç¬¬ä¸€æ‰¹æ•°æ®
   - `transferred_tokens` - å·²ä¼ è¾“tokenæ•°

---

## ğŸ“ ä»£ç ç¤ºä¾‹

### Languageä¾§

```python
# 1. é¦–æ¬¡åˆ†é…
allocation = allocator.alloc_default(req_id=req.rid)
receiver.init(allocation)

# 2. æ£€æŸ¥æ˜¯å¦éœ€è¦resume
if total_length > default_buffer_tokens:
    # ä¿å­˜ç¬¬ä¸€æ‰¹
    buffered_chunks = save_first_batch(...)
    transferred_tokens = default_buffer_tokens
    
    # é‡æ–°åˆ†é…
    allocator.free(allocation, req_id)
    new_allocation = allocator.alloc(num_tokens=remaining, req_id)
    
    # Resume
    receiver.resume_transfer(new_allocation, sent_tokens=transferred_tokens)

# 3. æ‹¼æ¥æ•°æ®
if transferred_tokens > 0:
    full_embeddings = torch.cat([buffered_chunks["embeddings"], new_embeddings])
```

### Embeddingä¾§

```python
# 1. æŒ‰å®é™…é•¿åº¦åˆ†é…
actual_length = req.embedding.shape[0]  # 2000
allocation = allocator.alloc(num_tokens=actual_length, req_id=req.rid)

# 2. å‘é€æ•°æ®
if sent_tokens == 0:
    # é¦–æ¬¡ï¼šé™åˆ¶ä¸º1024
    is_last = actual_length <= 1024
    chunk_info = buffers.get_buf_chunk_info(allocation, 0, max_tokens=1024)
else:
    # Resumeï¼šå‘é€å‰©ä½™
    is_last = True
    chunk_info = buffers.get_buf_chunk_info(allocation, sent_tokens)
```

---

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- `MULTIMODAL_CACHE_DESIGN.md` - å®Œæ•´è®¾è®¡æ–‡æ¡£
- `DESIGN_FIX_SUMMARY.md` - è®¾è®¡ä¿®æ­£è¯´æ˜
- `FINAL_IMPLEMENTATION_SUMMARY.md` - å®ç°æ€»ç»“

---

## âœ… çŠ¶æ€

- âœ… ä»£ç å®ç°å®Œæˆ
- âœ… Linteræ£€æŸ¥é€šè¿‡ï¼ˆ0é”™è¯¯ï¼‰
- âœ… è®¾è®¡é—®é¢˜å·²ä¿®æ­£
- âœ… å‘½åå·²ä¸“ä¸šåŒ–
- âš ï¸ é›†æˆæµ‹è¯•å¾…æ‰§è¡Œ

---

## ğŸ“ é—®é¢˜æ’æŸ¥

### æ—¥å¿—å…³é”®è¯

```bash
# ç›‘æ§Resumeç›¸å…³æ—¥å¿—
tail -f logs/*.log | grep -E "resume|transferred_tokens"

# æŸ¥çœ‹åˆ†é…ä¿¡æ¯
tail -f logs/*.log | grep -E "alloc_default|start_block"
```

### å¸¸è§é—®é¢˜

**Q: Languageä¾§é¢‘ç¹ç­‰å¾…bufferï¼Ÿ**
```bash
# å¢åŠ é»˜è®¤blockæ•°é‡
export SGLANG_DEFAULT_MULTIMODAL_BLOCKS=16
```

**Q: Resumeæ¯”ä¾‹è¿‡é«˜ï¼Ÿ**
```bash
# å¢åŠ é»˜è®¤blockæ•°é‡ï¼Œå‡å°‘resumeæ¬¡æ•°
export SGLANG_DEFAULT_MULTIMODAL_BLOCKS=16
```

---

**å®ç°å®Œæˆ**: 2025-10-20  
**ç‰ˆæœ¬**: v5.0-final  
**çŠ¶æ€**: âœ… Ready for Testing
