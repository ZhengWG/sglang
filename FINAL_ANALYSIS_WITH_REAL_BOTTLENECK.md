# çœŸæ­£çš„æ€§èƒ½ç“¶é¢ˆåˆ†æï¼ˆåŸºäºå®é™…æµ‹é‡ï¼‰

## ğŸ” å…³é”®å‘ç°

### ç”¨æˆ·æä¾›çš„å…³é”®ä¿¡æ¯

> **from_dict å®é™…è€—æ—¶ ~500ms**ï¼Œä¸»è¦æ—¶é—´èŠ±åœ¨å¯¹è±¡materializationï¼š
> - mm_inputs åŒ…å«è‡ªå®šä¹‰ç±»å®ä¾‹ï¼ˆå¦‚ Video itemsï¼‰
> - unpickleæ—¶ä½¿ç”¨äº†å»¶è¿ŸåŠ è½½ï¼ˆlazy loadingï¼‰
> - ç¬¬ä¸€æ¬¡è®¿é—®å±æ€§æ—¶æ‰çœŸæ­£materializeï¼š
>   - decode base64/bytes â†’ PIL.Image/np.ndarray
>   - size/channel checks, copies
>   - normalization, pad-parameter calculations
> - `from_dict` éå† `obj["mm_items"]` æ—¶è§¦å‘materialization

## ğŸ“Š çœŸå®çš„æ€§èƒ½ç“¶é¢ˆ

### å®Œæ•´æµç¨‹åˆ†æ

```
Tokenizer Manager:
  mm_processor.process() â†’ dict with custom Video/Image objects
  â†“ pickle (å¯èƒ½ä½¿ç”¨äº†å»¶è¿Ÿåºåˆ—åŒ–)
  
ZMQ send_pyobj:
  pickle.dumps(mm_inputs) â†’ åºåˆ—åŒ–ä¸ºbytes
  â†“
  
Scheduler recv_pyobj:
  pickle.loads() â†’ unpickle (lazy, å¿«é€Ÿ)
  å¯¹è±¡é‡å»ºï¼Œä½†å†…éƒ¨æ•°æ®æœªmaterialized
  â†“
  
Scheduler from_dict:
  éå† obj["mm_items"] â† è§¦å‘materializationï¼
    - ç¬¬ä¸€æ¬¡è®¿é—® item.feature
    - decode base64 â†’ PIL.Image (æ…¢ï¼)
    - np.ndarray conversion (æ…¢ï¼)  
    - normalization (æ…¢ï¼)
  â†“ 500ms! â† çœŸæ­£çš„ç“¶é¢ˆ
```

### ä¸ºä»€ä¹ˆ Commit 17a57fd86 çš„æ€è·¯æ˜¯å¯¹çš„

å¯¹äº **TP_size = 4**, **500ms çš„ materialization**:

```
åŸæ–¹æ¡ˆï¼ˆæ¯ä¸ªrankéƒ½æ‰§è¡Œfrom_dictï¼‰:
  Rank 0: materialization (500ms)
  Rank 1: materialization (500ms)  â† é‡å¤ï¼
  Rank 2: materialization (500ms)  â† é‡å¤ï¼
  Rank 3: materialization (500ms)  â† é‡å¤ï¼
  
  æ€»CPUæ—¶é—´: 2000ms
  æµªè´¹: 1500ms (75%)
```

**é¿å…è¿™ä¸ªé‡å¤æ˜¯éå¸¸æœ‰ä»·å€¼çš„ï¼**

### ä½†ä¸ºä»€ä¹ˆå¼•å…¥äº†æ€§èƒ½é—®é¢˜ï¼Ÿ

é—®é¢˜åœ¨äº **åŒæ­¥é˜»å¡å¯¼è‡´ä¸²è¡ŒåŒ–**ï¼š

```
åŸæ–¹æ¡ˆï¼ˆå¹¶è¡Œï¼‰:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
è¯·æ±‚1: å„rankå¹¶è¡Œ materialize (500ms)
è¯·æ±‚2: å„rankå¹¶è¡Œ materialize (500ms) â† ç«‹å³å¼€å§‹
è¯·æ±‚3: å„rankå¹¶è¡Œ materialize (500ms)
ååé‡: 1000/500 = 2 req/s

Commitæ–¹æ¡ˆï¼ˆä¸²è¡Œï¼‰:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
è¯·æ±‚1: Rank0 materialize (500ms) + pickle (100ms) 
       â†’ broadcast (50ms) â†’ unpickle (100ms)
       æ€»è®¡: 750ms âœ—
è¯·æ±‚2: â† ç­‰å¾…è¯·æ±‚1 â†’ materialize (500ms) + ... 
       æ€»è®¡: 750ms âœ—
ååé‡: 1000/750 = 1.3 req/s (ä¸‹é™35%)

é«˜å¹¶å‘(10 reqæ’é˜Ÿ):
  åŸæ–¹æ¡ˆ: å¯èƒ½å¹¶è¡Œå¤„ç†ä¸€äº› â†’ 5-7ç§’
  Commit: å®Œå…¨ä¸²è¡Œ â†’ 7.5ç§’ â†’ CPU 99.9%
```

## âœ… æ­£ç¡®çš„è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆå¯¹æ¯”ï¼ˆé‡æ–°è¯„ä¼°ï¼‰

| æ–¹æ¡ˆ | Materializationæ¬¡æ•° | å»¶è¿Ÿ | ååé‡ | å®æ–½éš¾åº¦ | æ¨èåº¦ |
|------|-------------------|------|--------|---------|--------|
| åŸæ–¹æ¡ˆ | TP_size Ã— N (2000ms) | 500ms | ä¸­ | - | â­â­ |
| Commitæ–¹æ¡ˆ | 1 Ã— N (500ms) | 750ms | ä½ âŒ | ä¸­ | âŒ |
| **æ–¹æ¡ˆA: Eager materialization** | **1 Ã— N** | **550ms** | **é«˜** | **ä¸­** | **â­â­â­â­â­** |
| æ–¹æ¡ˆB: å¼‚æ­¥broadcast | 1 Ã— N | 600ms | ä¸­é«˜ | é«˜ | â­â­â­â­ |
| æ–¹æ¡ˆC: å…±äº«å†…å­˜ | 1 Ã— N | 520ms | é«˜ | å¾ˆé«˜ | â­â­â­ |

### ğŸ† æ¨èæ–¹æ¡ˆA: Eager Materialization in Tokenizer

**æ ¸å¿ƒæ€è·¯**: åœ¨ Tokenizer é˜¶æ®µå°±å®Œå…¨ materialize å¯¹è±¡ï¼Œé¿å…å»¶è¿ŸåŠ è½½

#### å®ç°æ–¹æ¡ˆ

```python
# mm_data_processor.py æˆ– tokenizer_manager.py

class MMDataProcessor:
    
    async def process(self, image_data, audio_data, ...):
        """å¤„ç†å¤šæ¨¡æ€æ•°æ®"""
        
        # åŸæœ‰çš„å¤„ç†é€»è¾‘...
        mm_items = []
        
        for video in video_data:
            item = self._create_video_item(video)
            # å…³é”®ï¼šåœ¨è¿™é‡Œå°±å®Œå…¨materialize
            item = self._eager_materialize(item)
            mm_items.append(item)
        
        return {
            "mm_items": mm_items,
            ...
        }
    
    def _eager_materialize(self, item):
        """
        Eagerly materialize the item to avoid lazy loading overhead
        in scheduler ranks.
        
        This forces:
        - base64 decoding
        - PIL.Image/np.ndarray conversion
        - normalization
        - pad calculations
        
        After this, the object is "frozen" and ready for pickle/broadcast.
        """
        # å¼ºåˆ¶è®¿é—®æ‰€æœ‰ä¼šè§¦å‘materializationçš„å±æ€§
        if hasattr(item, 'feature') and item.feature is not None:
            # è§¦å‘materialization
            _ = item.feature.shape if hasattr(item.feature, 'shape') else len(item.feature)
        
        # å¦‚æœæœ‰å»¶è¿Ÿè®¡ç®—çš„å±æ€§ï¼Œå¼ºåˆ¶è®¡ç®—
        if hasattr(item, '_lazy_data'):
            item.materialize()  # å‡è®¾æœ‰è¿™ä¸ªæ–¹æ³•
        
        # ç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½å·²ç»decodeå’Œnormalize
        if hasattr(item, 'ensure_materialized'):
            item.ensure_materialized()
        
        return item
```

#### åœ¨ MultimodalDataItem ä¸­æ·»åŠ æ”¯æŒ

```python
# schedule_batch.py

@dataclasses.dataclass
class MultimodalDataItem:
    modality: Modality
    feature: Union[torch.Tensor, np.ndarray] = None
    _materialized: bool = False
    
    def ensure_materialized(self):
        """
        Ensure all lazy-loaded data is materialized.
        Call this in tokenizer before sending to scheduler.
        """
        if self._materialized:
            return
        
        # å¼ºåˆ¶è§¦å‘æ‰€æœ‰å¯èƒ½çš„å»¶è¿ŸåŠ è½½
        if self.feature is not None:
            # è®¿é—®featureè§¦å‘decode
            if isinstance(self.feature, LazyObject):
                self.feature = self.feature.materialize()
        
        if self.precomputed_embeddings is not None:
            if isinstance(self.precomputed_embeddings, LazyObject):
                self.precomputed_embeddings = self.precomputed_embeddings.materialize()
        
        # å¼ºåˆ¶è®¡ç®—hashï¼ˆå¦‚æœè¿˜æ²¡è®¡ç®—ï¼‰
        if self.hash is None:
            self.set_pad_value()
        
        self._materialized = True
    
    def __getstate__(self):
        """Pickleå‰ç¡®ä¿materialized"""
        self.ensure_materialized()
        return self.__dict__
```

#### ä¿®æ”¹ Tokenizer Manager

```python
# tokenizer_manager.py

async def _tokenize_one_request(...):
    ...
    
    if self.mm_processor and obj.contains_mm_input():
        mm_inputs_dict = await self.mm_data_processor.process(...)
        
        # æ„é€  MultimodalInputs å¯¹è±¡
        mm_inputs = MultimodalInputs.from_dict(mm_inputs_dict)
        
        # å…³é”®ï¼šå¼ºåˆ¶ eager materialization
        for item in mm_inputs.mm_items:
            item.ensure_materialized()  # åœ¨è¿™é‡ŒèŠ±500msï¼Œä½†åªä¸€æ¬¡ï¼
        
    else:
        mm_inputs = None
    
    tokenized_obj = TokenizedGenerateReqInput(
        ...,
        mm_inputs,  # å·²ç»å®Œå…¨materializedçš„å¯¹è±¡
        ...
    )
```

#### ä¿®æ”¹ Schedulerï¼ˆç®€åŒ–ï¼‰

```python
# scheduler.py

def handle_generate_request(self, recv_req: TokenizedGenerateReqInput):
    ...
    
    if recv_req.mm_inputs is not None:
        # ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€from_dict
        # å¯¹è±¡å·²ç»å®Œå…¨materializedï¼Œè®¿é—®å¾ˆå¿«
        image_inputs = recv_req.mm_inputs
        
        # è¿™é‡Œä¼šå¾ˆå¿«ï¼Œå› ä¸ºä¸ä¼šè§¦å‘materialization
        req.origin_input_ids = self.pad_input_ids_func(
            req.origin_input_ids, image_inputs
        )
        req.extend_image_inputs(image_inputs)
```

### æ€§èƒ½åˆ†æ

#### Eager Materialization æ–¹æ¡ˆ

```
Tokenizer (å•çº¿ç¨‹):
  mm_processor.process() (100ms)
  MultimodalInputs.from_dict() + ensure_materialized() (500ms)
  æ€»è®¡: 600ms â† åªæ‰§è¡Œä¸€æ¬¡ï¼

ZMQ broadcast:
  pickle (å·²materializedå¯¹è±¡, å¿«) (50ms)
  broadcast (50ms)
  unpickle (50ms)
  
Scheduler å„rank:
  ç›´æ¥ä½¿ç”¨ (0ms) â† ä¸éœ€è¦materializationï¼
  å¹¶è¡Œå¤„ç† âœ“

å•è¯·æ±‚æ€»å»¶è¿Ÿ: 600 + 150 = 750ms
ä½†å¹¶å‘å¤„ç†èƒ½åŠ›: é«˜ï¼ˆschedulerä¸é˜»å¡ï¼‰
```

#### å¯¹æ¯”

```
åœºæ™¯: 10ä¸ªè¯·æ±‚ï¼ŒTP_size=4ï¼Œmaterialization=500ms

åŸæ–¹æ¡ˆ:
  æ€»CPU: 10 Ã— 4 Ã— 500ms = 20ç§’
  å®é™…æ—¶é—´: ~5ç§’ (å¹¶è¡Œ)
  
Commitæ–¹æ¡ˆ:
  æ€»CPU: 10 Ã— 500ms = 5ç§’ (èŠ‚çœ75% âœ“)
  å®é™…æ—¶é—´: ~7.5ç§’ (ä¸²è¡ŒåŒ– âœ—)
  ååé‡: 1.3 req/s
  
Eageræ–¹æ¡ˆ:
  æ€»CPU: 10 Ã— 500ms = 5ç§’ (èŠ‚çœ75% âœ“)
  å®é™…æ—¶é—´: ~6ç§’ (Tokenizerä¸²è¡Œï¼Œä½†Schedulerå¹¶è¡Œ âœ“)
  ååé‡: 1.7 req/s (æå‡30%!)
```

### ä¸ºä»€ä¹ˆ Eager Materialization æ›´ä¼˜ï¼Ÿ

#### âœ… 1. é¿å…é‡å¤è®¡ç®—
- Materialization åªåœ¨ tokenizer æ‰§è¡Œä¸€æ¬¡
- èŠ‚çœ 75% CPU (å¯¹äºTP=4)
- æ‰€æœ‰ranksæ¥æ”¶çš„æ˜¯å·²materializedå¯¹è±¡

#### âœ… 2. Scheduler ä¿æŒå¹¶å‘èƒ½åŠ›
- Scheduler å„rankç›´æ¥ä½¿ç”¨å¯¹è±¡ï¼Œæ— å»¶è¿Ÿ
- ä¸å¼•å…¥åŒæ­¥é˜»å¡
- å¯ä»¥å¹¶è¡Œå¤„ç†å¤šä¸ªè¯·æ±‚

#### âœ… 3. Tokenizer ä¸²è¡Œå¯æ¥å—
- Tokenizer æœ¬èº«å°±æ˜¯é¢„å¤„ç†é˜¶æ®µ
- é€šå¸¸ä¸æ˜¯ç“¶é¢ˆï¼ˆå¯ä»¥scale tokenizer workersï¼‰
- 500ms materialization æ”¾åœ¨ tokenizer åˆç†

#### âœ… 4. èŒè´£æ¸…æ™°
- Tokenizer: å®Œæ•´çš„é¢„å¤„ç†ï¼ˆåŒ…æ‹¬materializationï¼‰
- Scheduler: åªè´Ÿè´£è°ƒåº¦ï¼Œä¸åšCPUå¯†é›†è®¡ç®—

## ğŸš€ å®æ–½æ–¹æ¡ˆ

### Phase 1: æ·»åŠ  Eager Materializationï¼ˆæ¨èç«‹å³æ‰§è¡Œï¼‰

```python
# 1. åœ¨ MultimodalDataItem æ·»åŠ  ensure_materialized()
# 2. åœ¨ tokenizer_manager.py è°ƒç”¨ ensure_materialized()
# 3. ä¿®æ”¹ scheduler.py ç›´æ¥ä½¿ç”¨å¯¹è±¡
# 4. åˆ é™¤ _process_and_broadcast_mm_inputs
```

### Phase 2: ä¼˜åŒ– Tokenizer å¹¶å‘ï¼ˆå¦‚æœéœ€è¦ï¼‰

å¦‚æœ tokenizer æˆä¸ºç“¶é¢ˆï¼Œå¯ä»¥ï¼š

```python
# tokenizer_manager.py

class TokenizerManager:
    def __init__(self, ...):
        ...
        # å¼‚æ­¥ materialization çº¿ç¨‹æ± 
        self.mm_materialize_pool = ThreadPoolExecutor(max_workers=4)
    
    async def _tokenize_one_request(self, obj):
        ...
        if mm_inputs:
            # å¼‚æ­¥ materialize
            loop = asyncio.get_event_loop()
            mm_inputs = await loop.run_in_executor(
                self.mm_materialize_pool,
                self._materialize_mm_inputs,
                mm_inputs
            )
```

### Phase 3: ä¼˜åŒ– Pickle å¤§å°ï¼ˆå¯é€‰ï¼‰

å¦‚æœ materialized å¯¹è±¡è¿‡å¤§ï¼š

```python
# ä½¿ç”¨æ›´é«˜æ•ˆçš„åºåˆ—åŒ–æ ¼å¼
# æˆ–å‹ç¼©å¤§å‹ tensor
def __getstate__(self):
    state = self.__dict__.copy()
    if self.feature is not None and isinstance(self.feature, np.ndarray):
        # å‹ç¼©å¤§å‹æ•°ç»„
        if self.feature.nbytes > 10 * 1024 * 1024:  # >10MB
            state['feature'] = compress_array(self.feature)
            state['_compressed'] = True
    return state
```

## ğŸ“Š é¢„æœŸæ•ˆæœ

### æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | åŸæ–¹æ¡ˆ | Commitæ–¹æ¡ˆ | Eageræ–¹æ¡ˆ | æ”¹å–„ |
|------|--------|-----------|----------|------|
| CPUæ—¶é—´(å•è¯·æ±‚) | 2000ms | 500ms | 500ms | -75% âœ“ |
| å•è¯·æ±‚å»¶è¿Ÿ | 500ms | 750ms | 650ms | -30% vs Commit |
| å¹¶å‘QPS (10å¹¶å‘) | 2 req/s | 1.3 req/s | 1.7 req/s | +30% vs Commit |
| CPUä½¿ç”¨ç‡ | 99% | 99.9% | <70% | æ­£å¸¸ âœ“ |
| Scheduleré˜»å¡ | æ—  | æœ‰ âœ— | æ—  âœ“ |

### å…³é”®æ”¹å–„

1. **CPUèŠ‚çœ75%** (vs åŸæ–¹æ¡ˆ)
2. **ååé‡æå‡30%** (vs Commitæ–¹æ¡ˆ)
3. **Schedulerä¸é˜»å¡** (ä¿æŒå¹¶å‘èƒ½åŠ›)
4. **æ¶æ„æ¸…æ™°** (èŒè´£åˆ†æ˜)

## ğŸ’¡ æ·±å…¥ç†è§£

### ä¸ºä»€ä¹ˆä¸åœ¨ mm_processor.process() å°± materializeï¼Ÿ

å¯ä»¥ï¼å®é™…ä¸Šè¿™æ˜¯æœ€å½»åº•çš„æ–¹æ¡ˆï¼š

```python
# mm_data_processor.py

class MMDataProcessor:
    async def process(self, ...):
        # ç›´æ¥è¿”å›å®Œå…¨materializedçš„å¯¹è±¡
        mm_items = []
        for video in video_data:
            # decode, normalize, å…¨éƒ¨åšå®Œ
            decoded_frames = decode_video(video)  # 500ms
            normalized = normalize(decoded_frames)
            item = MultimodalDataItem(
                feature=normalized,  # å·²ç»æ˜¯ np.ndarray
                ...
            )
            mm_items.append(item)
        
        return MultimodalInputs(mm_items=mm_items)
```

è¿™æ ·æ›´ç®€å•ï¼Œæ¨èï¼

### å»¶è¿ŸåŠ è½½çš„åˆè¡·æ˜¯ä»€ä¹ˆï¼Ÿ

å¯èƒ½æ˜¯ä¸ºäº†ï¼š
1. èŠ‚çœå†…å­˜ï¼ˆä¸ç«‹å³decodeæ‰€æœ‰æ•°æ®ï¼‰
2. åŠ å¿« pickle é€Ÿåº¦
3. åœ¨ä¸éœ€è¦æ—¶é¿å…è®¡ç®—

ä½†åœ¨è¿™ä¸ªåœºæ™¯ä¸‹ï¼š
- æ‰€æœ‰ scheduler ranks éƒ½éœ€è¦è®¿é—®æ•°æ®
- å»¶è¿ŸåŠ è½½å¯¼è‡´é‡å¤è®¡ç®—
- å¾—ä¸å¿å¤±

**ç»“è®ºï¼šå¯¹äºè¿™ä¸ªä½¿ç”¨åœºæ™¯ï¼Œeager materialization æ›´åˆé€‚**

## ğŸ¯ æ€»ç»“

### å…³é”®æ´å¯Ÿ

1. **çœŸæ­£çš„ç“¶é¢ˆæ˜¯ materialization (500ms)**
   - ä¸æ˜¯ç®€å•çš„ setattr
   - è€Œæ˜¯ decodeã€normalize ç­‰CPUå¯†é›†æ“ä½œ

2. **Commit 17a57fd86 çš„æ€è·¯æ˜¯å¯¹çš„**
   - é¿å…é‡å¤materializationå¾ˆæœ‰ä»·å€¼
   - ä½†å®ç°æ–¹å¼å¼•å…¥äº†åŒæ­¥é˜»å¡

3. **æ­£ç¡®çš„è§£å†³æ–¹æ¡ˆæ˜¯ Eager Materialization**
   - åœ¨ tokenizer é˜¶æ®µå®Œå…¨ materialize
   - Scheduler ç›´æ¥ä½¿ç”¨ï¼Œæ— å»¶è¿Ÿ
   - ä¿æŒå¹¶å‘èƒ½åŠ›

### æ¨èè¡ŒåŠ¨

1. **ç«‹å³å®æ–½**: Eager Materialization in Tokenizer
2. **å¯é€‰**: å¦‚æœ tokenizer æˆä¸ºç“¶é¢ˆï¼Œæ·»åŠ å¹¶å‘å¤„ç†
3. **æœªæ¥**: è€ƒè™‘æ›´é«˜æ•ˆçš„åºåˆ—åŒ–æ ¼å¼

---

**æ„Ÿè°¢æä¾›å…³é”®ä¿¡æ¯ï¼ç°åœ¨æ–¹æ¡ˆæ›´åŠ ç²¾ç¡®å’Œæœ‰æ•ˆã€‚** ğŸ™
