# å¤šæ¨¡æ€Embedding Resumeä¼ è¾“è®¾è®¡æ–¹æ¡ˆ

## ğŸ“‹ é—®é¢˜æè¿°

### å½“å‰é—®é¢˜
Languageä¾§æ¯æ¬¡ç”³è¯·blockæ˜¯æŒ‰ç…§**é»˜è®¤å€¼**ç”³è¯·çš„ï¼ˆç›®å‰æ˜¯8192 tokensï¼‰ï¼Œä½†Embeddingä¾§èƒ½è·å–**å®é™…çš„req_len**ï¼Œè¿™å¯¼è‡´`dst_embedding_indices`æ•°ç›®å¯èƒ½ä¼š**å°äº**Embeddingä¾§`embedding_indices`æ•°ç›®ã€‚

### ç¤ºä¾‹åœºæ™¯
```
å®é™…æƒ…å†µ: Embeddingä¾§éœ€è¦å‘é€2000 tokensçš„æ•°æ®
Languageä¾§: é»˜è®¤åˆ†é…1024 tokens (8 blocks * 128 tokens/block)
é—®é¢˜: 1024 < 2000ï¼Œç›®æ ‡ç¼“å†²åŒºä¸è¶³
```

å½“å‰è¡Œä¸ºï¼ˆ`conn_multimodal.py` 233-238è¡Œï¼‰:
```python
if len(embedding_indices) > len(dst_embedding_indices):
    raise ValueError(
        f"Source blocks ({len(embedding_indices)}) cannot be greater than "
        f"destination blocks ({len(dst_embedding_indices)}). "
        f"Language side allocated insufficient buffer."
    )
```

---

## ğŸ¯ è§£å†³æ–¹æ¡ˆï¼šResumeä¼ è¾“æœºåˆ¶

### æ ¸å¿ƒæ€è·¯
å®ç°**ä¸¤é˜¶æ®µä¼ è¾“**æœºåˆ¶ï¼š
1. **ç¬¬ä¸€é˜¶æ®µ**: Languageä¾§æŒ‰é»˜è®¤å€¼åˆ†é… â†’ Embeddingä¾§å‘é€éƒ¨åˆ†æ•°æ®
2. **é€šçŸ¥é˜¶æ®µ**: Embeddingä¾§å‘ŠçŸ¥Languageå®é™…é•¿åº¦
3. **ç¬¬äºŒé˜¶æ®µ**: Languageä¾§é‡æ–°åˆ†é…å‰©ä½™ç©ºé—´ â†’ Embeddingä¾§å‘é€å‰©ä½™æ•°æ®

---

## ğŸ—ï¸ è®¾è®¡æ–¹æ¡ˆ

### 1. æ•°æ®ç»“æ„ä¿®æ”¹

#### 1.1 `TransferEmbeddingInfo` (conn_multimodal.py)
æ·»åŠ å­—æ®µè·Ÿè¸ªä¼ è¾“è¿›åº¦ï¼š

```python
@dataclasses.dataclass
class TransferEmbeddingInfo:
    room: int
    endpoint: str
    dst_port: int
    mooncake_session_id: str
    dst_embedding_indices: List[int]
    required_dst_info_num: int
    sent_tokens: int = 0           # æ–°å¢ï¼šå·²å‘é€çš„tokenæ•°
    allocated_tokens: int = 0      # æ–°å¢ï¼šLanguageä¾§åˆ†é…çš„tokenæ•°
```

#### 1.2 Resumeè¯·æ±‚æ¶ˆæ¯æ ¼å¼
åœ¨ZMQæ¶ˆæ¯ä¸­æ·»åŠ resumeä¿¡æ¯ï¼š

```python
# åˆå§‹åŒ–æ¶ˆæ¯ï¼ˆinitï¼‰
[
    str(room).encode("ascii"),
    endpoint.encode("ascii"),
    str(dst_port).encode("ascii"),
    session_id.encode("ascii"),
    embedding_indices_str.encode("ascii"),
    str(required_dst_info_num).encode("ascii"),
    str(allocated_tokens).encode("ascii"),  # æ–°å¢
]

# Resumeæ¶ˆæ¯ï¼ˆresume_transferï¼‰
[
    str(room).encode("ascii"),
    endpoint.encode("ascii"),
    str(dst_port).encode("ascii"),
    session_id.encode("ascii"),
    embedding_indices_str.encode("ascii"),
    str(required_dst_info_num).encode("ascii"),
    str(sent_tokens).encode("ascii"),       # æ–°å¢ï¼šå·²å‘é€çš„tokenæ•°
    str(allocated_tokens).encode("ascii"),  # æ–°å¢ï¼šæ–°åˆ†é…çš„tokenæ•°
]
```

---

### 2. Languageä¾§ä¿®æ”¹ (multimodal_language.py)

#### 2.1 åœ¨`MultimodalLanguagePreallocQueue`ä¸­é…ç½®é»˜è®¤bufferå¤§å°

```python
class MultimodalLanguagePreallocQueue:
    def __init__(self, ...):
        # ç°æœ‰ä»£ç ...
        # é»˜è®¤åˆ†é…çš„tokenæ•°ï¼ˆé¦–æ¬¡åˆ†é…ä½¿ç”¨ï¼‰
        self.default_allocate_tokens = int(
            os.getenv("SGLANG_EMBEDDING_DEFAULT_ALLOCATE_BUFFER_SIZE", "8192")
        )
        # æ³¨æ„ï¼šresumeé€»è¾‘åœ¨MultimodalLanguageTransferQueueä¸­å¤„ç†ï¼Œä¸éœ€è¦å•ç‹¬çš„é˜Ÿåˆ—
```

#### 2.2 ä¿®æ”¹`MooncakeEmbeddingReceiver.init()`æ–¹æ³•

æ·»åŠ `allocated_tokens`å‚æ•°ï¼š
```python
def init(
    self,
    embedding_indices: Optional[List[int]] = None,
    allocated_tokens: Optional[int] = None,  # æ–°å¢
):
    if embedding_indices is not None:
        embedding_indices_str = ",".join(str(idx) for idx in embedding_indices)
    else:
        embedding_indices_str = ""
    
    # è®¡ç®—allocated_tokens
    if allocated_tokens is None:
        block_size = self.embedding_mgr.data_args.aux_item_lens[1] // 4
        allocated_tokens = len(embedding_indices) * block_size
    
    for bootstrap_info in self.bootstrap_infos:
        # ...å‘é€æ¶ˆæ¯ï¼ŒåŒ…å«allocated_tokens
        sock.send_multipart([
            str(self.bootstrap_room).encode("ascii"),
            get_local_ip_by_remote().encode("ascii"),
            str(self.embedding_mgr.rank_port).encode("ascii"),
            self.session_id.encode("ascii"),
            embedding_indices_str.encode("ascii"),
            str(self.required_dst_info_num).encode("ascii"),
            str(allocated_tokens).encode("ascii"),  # æ–°å¢
        ])
```

#### 2.3 æ·»åŠ Resumeä¼ è¾“æ–¹æ³•

```python
class MooncakeEmbeddingReceiver(BaseKVReceiver):
    def resume_transfer(
        self,
        embedding_indices: List[int],
        sent_tokens: int,
        allocated_tokens: int,
    ):
        """Resume transfer with new allocation after partial transfer.
        
        Args:
            embedding_indices: New block allocation for remaining data
            sent_tokens: Number of tokens already transferred
            allocated_tokens: Number of tokens in new allocation
        """
        embedding_indices_str = ",".join(str(idx) for idx in embedding_indices)
        
        for bootstrap_info in self.bootstrap_infos:
            self.embedding_server_url = (
                f"{bootstrap_info['rank_ip']}:{bootstrap_info['rank_port']}"
            )
            
            sock, lock = self._connect("tcp://" + self.embedding_server_url)
            with lock:
                sock.send_multipart([
                    str(self.bootstrap_room).encode("ascii"),
                    get_local_ip_by_remote().encode("ascii"),
                    str(self.embedding_mgr.rank_port).encode("ascii"),
                    self.session_id.encode("ascii"),
                    embedding_indices_str.encode("ascii"),
                    str(self.required_dst_info_num).encode("ascii"),
                    str(sent_tokens).encode("ascii"),      # æ ‡è¯†resume
                    str(allocated_tokens).encode("ascii"),  # æ–°åˆ†é…çš„å¤§å°
                ])
```

#### 2.4 ä¿®æ”¹`MultimodalLanguageTransferQueue.pop_transferred()`

æ£€æµ‹éƒ¨åˆ†ä¼ è¾“ï¼Œå¹¶è§¦å‘resumeï¼š
```python
def pop_transferred(self):
    # ...ç°æœ‰ä»£ç ...
    
    for i, (language_req, poll) in enumerate(zip(self.queue, polls)):
        if poll == KVPoll.Transferring:  # æ–°çŠ¶æ€ï¼šéƒ¨åˆ†ä¼ è¾“å®Œæˆ
            # è·å–å®é™…éœ€è¦çš„æ€»é•¿åº¦
            block_indices = language_req.embedding_indices
            embedding_data, fill_ids, mrope_positions, aux_datas = (
                self.metadata_buffers.get_buf(block_indices=block_indices)
            )
            actual_total_length = aux_datas[0]  # å®é™…æ€»é•¿åº¦
            sent_tokens = len(fill_ids)          # å·²å‘é€çš„tokenæ•°
            
            if actual_total_length > sent_tokens:
                # éœ€è¦resumeä¼ è¾“
                remaining_tokens = actual_total_length - sent_tokens
                
                # ç¼“å­˜å·²æ¥æ”¶çš„æ•°æ®
                language_req.req.partial_input_embeds = embedding_data
                language_req.req.partial_fill_ids = fill_ids.tolist()
                language_req.req.partial_mrope_positions = mrope_positions
                language_req.req.partial_aux_datas = aux_datas
                
                # é‡Šæ”¾æ—§çš„åˆ†é…
                self.req_to_metadata_buffer_idx_allocator.free(
                    block_indices=block_indices,
                    req_id=language_req.req.rid,
                    fake=isinstance(language_req.embedding_receiver, FakeKVReceiver),
                )
                
                # é‡æ–°åˆ†é…å‰©ä½™ç©ºé—´
                new_allocation = self.req_to_metadata_buffer_idx_allocator.alloc(
                    num_tokens=remaining_tokens,
                    req_id=language_req.req.rid,
                    fake=isinstance(language_req.embedding_receiver, FakeKVReceiver),
                )
                
                if new_allocation is None:
                    # å†…å­˜ä¸è¶³ï¼Œç¨åé‡è¯•
                    logger.warning(f"Not enough memory to resume transfer for {language_req.req.rid}")
                    continue
                
                # æ›´æ–°embedding_indices
                language_req.embedding_indices = new_allocation
                
                # å‘é€resumeè¯·æ±‚
                language_req.embedding_receiver.resume_transfer(
                    embedding_indices=new_allocation,
                    sent_tokens=sent_tokens,
                    allocated_tokens=remaining_tokens,
                )
                
                # ç»§ç»­ç­‰å¾…
                continue
        
        elif poll == KVPoll.Success:
            # å®Œæ•´ä¼ è¾“å®Œæˆ
            # å¦‚æœæœ‰partialæ•°æ®ï¼Œéœ€è¦åˆå¹¶
            if hasattr(language_req.req, 'partial_input_embeds'):
                # åˆå¹¶æ•°æ®
                new_embedding_data, new_fill_ids, new_mrope_positions, _ = (
                    self.metadata_buffers.get_buf(block_indices=language_req.embedding_indices)
                )
                
                language_req.req.input_embeds = torch.cat([
                    language_req.req.partial_input_embeds,
                    new_embedding_data
                ])
                language_req.req.origin_input_ids = (
                    language_req.req.partial_fill_ids + new_fill_ids.tolist()
                )
                # åˆå¹¶mrope_positions...
                
                # æ¸…ç†partialæ•°æ®
                del language_req.req.partial_input_embeds
                del language_req.req.partial_fill_ids
                del language_req.req.partial_mrope_positions
                del language_req.req.partial_aux_datas
            else:
                # æ­£å¸¸å•æ¬¡ä¼ è¾“å®Œæˆ
                # ...ç°æœ‰ä»£ç ...
            
            transferred_reqs.append(language_req.req)
            indices_to_remove.add(i)
```

---

### 3. Embeddingä¾§ä¿®æ”¹ (multimodal_embedding.py)

#### 3.1 ä¿æŒ`send_embedding_chunk()`ä¸å˜

**é‡è¦è¯´æ˜**ï¼š`send_embedding_chunk()`ä¸­çš„`last_chunk`å‚æ•°æ˜¯ä¸º**chunk-prefill**è®¾è®¡çš„ï¼Œä¸è¦ä¸å½“å‰çš„**chunk-transferï¼ˆresumeï¼‰**æ··ç”¨ã€‚

Resumeä¼ è¾“é€»è¾‘å®Œå…¨åœ¨Connectionå±‚å¤„ç†ï¼Œ`send_embedding_chunk()`åœ¨é¦–æ¬¡è°ƒç”¨åä¸éœ€è¦å†æ¬¡è°ƒç”¨ã€‚

```python
def send_embedding_chunk(
    self: Scheduler,
    req: Req,
    last_chunk: bool = False,
):
    # ä¿æŒç°æœ‰å®ç°ä¸å˜
    # è¿™ä¸ªæ–¹æ³•åªåœ¨é¦–æ¬¡ä¼ è¾“æ—¶è°ƒç”¨ä¸€æ¬¡
    assert last_chunk == True  # For embedding models, always send once
    
    if last_chunk:
        self.disagg_metadata_buffers.set_buf(req)
    
    # Send using block_indices
    req.disagg_embedding_sender.send_embedding(
        embedding_indices=req.embedding_indices,
        last_chunk=last_chunk,
        total_tokens=len(req.fill_ids),
        block_size=self.disagg_metadata_buffers.block_size,
    )
```

#### 3.2 ä¿®æ”¹`MooncakeEmbeddingSender.send_embedding()`

åªåœ¨é¦–æ¬¡è°ƒç”¨æ—¶è§¦å‘transferï¼Œresumeç”±Languageä¾§ä¸»åŠ¨å‘èµ·ï¼š
```python
class MooncakeEmbeddingSender(BaseKVSender):
    def send_embedding(
        self,
        embedding_indices: List[int] = None,
        last_chunk: bool = True,
        total_tokens: int = None,
        block_size: int = None,
    ):
        """Send embedding data to language instances using block-based transfer.
        
        Note: 
            - è¿™ä¸ªæ–¹æ³•åªåœ¨é¦–æ¬¡ä¼ è¾“æ—¶è°ƒç”¨ä¸€æ¬¡
            - Resumeä¼ è¾“ç”±Languageä¾§é€šè¿‡resume_transfer()æ¶ˆæ¯è§¦å‘
            - Connectionå±‚ä¼šæ ¹æ®allocated_tokensè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦éœ€è¦éƒ¨åˆ†ä¼ è¾“
        
        Args:
            embedding_indices: List of source embedding indices
            last_chunk: Whether this is the last chunk (always True for embeddings)
            total_tokens: Total number of tokens to transfer
            block_size: Number of tokens per block
        """
        # é¦–æ¬¡ä¼ è¾“ï¼Œsent_tokens=0
        self.embedding_mgr.add_transfer_request(
            self.bootstrap_room,
            embedding_indices,
            is_last=last_chunk,
            total_tokens=total_tokens,
            block_size=block_size,
        )
```

---

### 4. Connectionå±‚ä¿®æ”¹ (conn_multimodal.py)

#### 4.1 ä¿®æ”¹`send_embedding()`æ–¹æ³•

**å…³é”®ä¿®æ”¹**ï¼šåŸºäº`allocated_tokens`è€Œéblockæ•°é‡æ¥åˆ¤æ–­bufferæ˜¯å¦è¶³å¤Ÿ

```python
def send_embedding(
    self,
    mooncake_session_id: str,
    embedding_indices: List[int],
    dst_embedding_ptrs: list[int],
    dst_embedding_indices: List[int],
    total_tokens: int,
    block_size: int,
    sent_tokens: int = 0,         # æ–°å¢ï¼šå·²å‘é€çš„tokenæ•°
    allocated_tokens: int = None,  # æ–°å¢ï¼šLanguageä¾§åˆ†é…çš„tokenæ•°
):
    """Send embedding data using block-based transfer.
    
    Args:
        sent_tokens: Number of tokens already sent (for resume transfer)
        allocated_tokens: Number of tokens allocated by Language side
    """
    # æ ¡éªŒblock_sizeä¸€è‡´æ€§
    if allocated_tokens is not None:
        expected_block_size = allocated_tokens // len(dst_embedding_indices)
        if expected_block_size != block_size:
            raise ValueError(
                f"Block size mismatch: Embedding side uses {block_size}, "
                f"but Language side allocated {allocated_tokens} tokens "
                f"for {len(dst_embedding_indices)} blocks "
                f"(implies block_size={expected_block_size})"
            )
    else:
        # å‘åå…¼å®¹ï¼šå¦‚æœæ²¡æœ‰allocated_tokensï¼Œç”¨blockæ•°é‡è®¡ç®—
        allocated_tokens = len(dst_embedding_indices) * block_size
    
    # åŸºäºallocated_tokensåˆ¤æ–­æ˜¯å¦éœ€è¦éƒ¨åˆ†ä¼ è¾“
    remaining_tokens = total_tokens - sent_tokens
    
    if remaining_tokens > allocated_tokens:
        # éœ€è¦éƒ¨åˆ†ä¼ è¾“
        logger.warning(
            f"Partial transfer: remaining={remaining_tokens} > "
            f"allocated={allocated_tokens}. Will transfer {allocated_tokens} tokens."
        )
        tokens_to_send = allocated_tokens
        is_partial = True
    else:
        # å¯ä»¥å®Œæ•´ä¼ è¾“
        tokens_to_send = remaining_tokens
        is_partial = False
    
    # è®¡ç®—è¦å‘é€çš„blockèŒƒå›´
    start_block = sent_tokens // block_size
    embedding_indices_to_send = embedding_indices[start_block:]
    
    # è®¡ç®—éœ€è¦çš„dst blockæ•°é‡
    dst_blocks_needed = (tokens_to_send + block_size - 1) // block_size
    
    # éªŒè¯dst bufferæ˜¯å¦è¶³å¤Ÿ
    if dst_blocks_needed > len(dst_embedding_indices):
        raise ValueError(
            f"Insufficient dst blocks: need {dst_blocks_needed} blocks "
            f"for {tokens_to_send} tokens, but only have {len(dst_embedding_indices)} blocks"
        )
    
    # é™åˆ¶ä¸ºå®é™…éœ€è¦çš„dst blocks
    dst_embedding_indices = dst_embedding_indices[:dst_blocks_needed]
    embedding_indices_to_send = embedding_indices_to_send[:dst_blocks_needed]
    
    src_addrs = []
    dst_addrs = []
    lengths = []
    
    # è®°å½•å®é™…ä¼ è¾“çš„tokenæ•°ï¼ˆç”¨äºè¿”å›ï¼‰
    tokens_transferred = 0
    
    for block_idx, (src_block_idx, dst_block_idx) in enumerate(
        zip(embedding_indices_to_send, dst_embedding_indices)
    ):
        # Calculate tokens in this block
        remaining_in_transfer = tokens_to_send - tokens_transferred
        tokens_in_block = min(block_size, remaining_in_transfer)
        
        if tokens_in_block <= 0:
            break
        
        # Transfer each buffer type within the block
        for buffer_type_idx in range(len(self.data_args.aux_item_lens)):
            embedding_item_len = self.data_args.aux_item_lens[buffer_type_idx]
            
            # Calculate chunk size
            if buffer_type_idx == 3:  # aux_datas
                if sent_tokens == 0 and block_idx == 0:  # åªåœ¨åˆæ¬¡ä¼ è¾“çš„ç¬¬ä¸€ä¸ªå—å‘é€
                    chunk_size = embedding_item_len
                else:
                    continue
            else:
                chunk_size = (embedding_item_len * tokens_in_block) // block_size
            
            embedding_addr = (
                self.data_args.aux_data_ptrs[buffer_type_idx]
                + src_block_idx * embedding_item_len
            )
            dst_embedding_addr = (
                dst_embedding_ptrs[buffer_type_idx]
                + dst_block_idx * embedding_item_len
            )
            
            src_addrs.append(embedding_addr)
            dst_addrs.append(dst_embedding_addr)
            lengths.append(chunk_size)
        
        tokens_transferred += tokens_in_block
    
    ret = self.engine.batch_transfer_sync(
        mooncake_session_id, src_addrs, dst_addrs, lengths
    )
    
    # è¿”å›ä¼ è¾“ç»“æœå’Œæ˜¯å¦ä¸ºéƒ¨åˆ†ä¼ è¾“
    return ret, is_partial
```

#### 4.2 ä¿®æ”¹`embedding_thread()`å¤„ç†Resumeæ¶ˆæ¯

```python
def embedding_thread():
    """This thread recvs pre-alloc notification from the language engine"""
    while True:
        waiting_req_bytes = self.server_socket.recv_multipart()
        room = waiting_req_bytes[0].decode("ascii")
        mooncake_session_id = waiting_req_bytes[3].decode("ascii")
        
        if room == "None":
            # æ³¨å†Œè¯·æ±‚
            self.language_args_table[mooncake_session_id] = (
                EmbeddingArgsRegisterInfo.from_zmq(waiting_req_bytes)
            )
            # ...ç°æœ‰ä»£ç ...
        else:
            room = int(room)
            
            # è§£ææ¶ˆæ¯
            dst_embedding_indices_str = waiting_req_bytes[4].decode("ascii")
            dst_embedding_indices = (
                [int(x) for x in dst_embedding_indices_str.split(",")]
                if dst_embedding_indices_str else []
            )
            required_dst_info_num = int(waiting_req_bytes[5].decode("ascii"))
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯resumeè¯·æ±‚ï¼ˆ7ä¸ªå­—æ®µï¼‰
            is_resume = len(waiting_req_bytes) >= 8
            
            if is_resume:
                # Resumeè¯·æ±‚
                sent_tokens = int(waiting_req_bytes[6].decode("ascii"))
                allocated_tokens = int(waiting_req_bytes[7].decode("ascii"))
                
                # æ›´æ–°ç°æœ‰transfer_info
                if room in self.transfer_infos and mooncake_session_id in self.transfer_infos[room]:
                    transfer_info = self.transfer_infos[room][mooncake_session_id]
                    transfer_info.sent_tokens = sent_tokens
                    transfer_info.allocated_tokens = allocated_tokens
                    transfer_info.dst_embedding_indices = dst_embedding_indices
                    
                    # ä¸é‡ç½®statusï¼Œä¿æŒå½“å‰çŠ¶æ€ï¼ˆTransferringï¼‰
                    logger.info(
                        f"Resume transfer for room={room}, sent_tokens={sent_tokens}, "
                        f"allocated_tokens={allocated_tokens}"
                    )
                else:
                    logger.error(f"Cannot resume: room={room} not found in transfer_infos")
            else:
                # åˆæ¬¡è¯·æ±‚
                allocated_tokens = int(waiting_req_bytes[6].decode("ascii"))
                
                if room not in self.transfer_infos:
                    self.transfer_infos[room] = {}
                
                self.transfer_infos[room][mooncake_session_id] = TransferEmbeddingInfo(
                    room=room,
                    endpoint=waiting_req_bytes[1].decode("ascii"),
                    dst_port=int(waiting_req_bytes[2].decode("ascii")),
                    mooncake_session_id=mooncake_session_id,
                    dst_embedding_indices=dst_embedding_indices,
                    required_dst_info_num=required_dst_info_num,
                    sent_tokens=0,
                    allocated_tokens=allocated_tokens,
                )
                
                # æ ‡è®°ä¸ºWaitingForInput
                if len(self.transfer_infos[room]) == required_dst_info_num:
                    self.update_status(room, KVPoll.WaitingForInput)
```

#### 4.3 ä¿®æ”¹`transfer_worker()`åˆ¤æ–­æ˜¯å¦å®Œæ•´ä¼ è¾“

```python
def transfer_worker(self, queue: FastQueue, executor: concurrent.futures.ThreadPoolExecutor):
    while True:
        try:
            embedding_chunk: TransferEmbeddingChunk = queue.get()
            # ...ç°æœ‰ä»£ç ...
            
            for req in reqs_to_be_processed:
                # è·å–allocated_tokenså’Œsent_tokens
                allocated_tokens = req.allocated_tokens
                sent_tokens = req.sent_tokens
                
                block_size = self.data_args.aux_item_lens[1] // 4
                
                # è°ƒç”¨send_embeddingï¼Œè¿”å›(ret, is_partial)
                ret, is_partial = self.send_embedding(
                    req.mooncake_session_id,
                    embedding_chunk.embedding_indices,
                    self.language_args_table[req.mooncake_session_id].dst_embedding_ptrs,
                    req.dst_embedding_indices,
                    embedding_chunk.total_tokens,  # ä¼ é€’æ€»tokenæ•°
                    block_size,
                    sent_tokens,                   # å·²å‘é€çš„tokenæ•°
                    allocated_tokens,              # Languageä¾§åˆ†é…çš„tokenæ•°
                )
                
                if ret != 0:
                    # ...é”™è¯¯å¤„ç†...
                    self.record_failure(
                        embedding_chunk.room,
                        f"Failed to send embedding chunk of {embedding_chunk.room} to {req.endpoint}:{req.dst_port}",
                    )
                    self.update_status(embedding_chunk.room, KVPoll.Failed)
                    self.sync_status_to_language_endpoint(
                        req.endpoint, req.dst_port, req.room, KVPoll.Failed
                    )
                    break
                
                # æ›´æ–°sent_tokens
                tokens_sent = min(embedding_chunk.total_tokens - sent_tokens, allocated_tokens)
                req.sent_tokens += tokens_sent
                
                polls.append(True)
                dst_ranks_infos.append((req.endpoint, req.dst_port, req.room))
                
                # æ ¹æ®is_partialè®¾ç½®çŠ¶æ€
                if len(polls) == req.required_dst_info_num:
                    if is_partial:
                        # éƒ¨åˆ†ä¼ è¾“å®Œæˆï¼Œç­‰å¾…resume
                        status = KVPoll.Transferring if all(polls) else KVPoll.Failed
                        # ä¿ç•™transfer_infosä»¥æ”¯æŒresume
                    else:
                        # å®Œæ•´ä¼ è¾“å®Œæˆ
                        status = KVPoll.Success if all(polls) else KVPoll.Failed
                    
                    self.update_status(req.room, status)
                    
                    for endpoint, dst_port, room in dst_ranks_infos:
                        self.sync_status_to_language_endpoint(
                            endpoint, dst_port, room, status
                        )
            
            # åªæœ‰å®Œå…¨æˆåŠŸæ—¶æ‰æ¸…ç†transfer_infos
            if (
                embedding_chunk.room in self.request_status
                and self.check_status(embedding_chunk.room) == KVPoll.Success
            ):
                if embedding_chunk.room in self.transfer_infos:
                    self.transfer_infos.pop(embedding_chunk.room)
        
        except Exception as e:
            raise RuntimeError(f"Transfer thread failed: {e}")
```

#### 4.4 æ·»åŠ é˜²æ­¢é‡å¤ä¼ è¾“çš„æ£€æŸ¥

```python
def add_transfer_request(
    self,
    bootstrap_room: int,
    embedding_indices: List[int],
    is_last: bool,
    total_tokens: int,
    block_size: int,
):
    """Add block-based transfer request to queue.
    
    Note:
        - è¿™ä¸ªæ–¹æ³•åªåœ¨é¦–æ¬¡ä¼ è¾“æ—¶è°ƒç”¨ï¼ˆç”±send_embeddingè§¦å‘ï¼‰
        - Resumeä¼ è¾“ç”±Languageä¾§å‘é€resumeæ¶ˆæ¯è§¦å‘ï¼Œä¸ç»è¿‡è¿™ä¸ªæ–¹æ³•
        - sent_tokensä¿¡æ¯åœ¨transfer_infosä¸­ç»´æŠ¤
    """
    assert self.disaggregation_mode == DisaggregationMode.ENCODE
    assert is_last  # For embedding data, we only send once at the end
    
    if bootstrap_room not in self.request_status or self.check_status(bootstrap_room) == KVPoll.Failed:
        return
    
    if bootstrap_room not in self.transfer_infos:
        return
    
    # é˜²æ­¢é‡å¤ä¼ è¾“ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»å¼€å§‹ä¼ è¾“
    current_status = self.check_status(bootstrap_room)
    if current_status in [KVPoll.Transferring, KVPoll.Success]:
        logger.debug(f"Skip duplicate transfer for room={bootstrap_room}, status={current_status}")
        return
    
    # ...ç°æœ‰ä»£ç ...
    self.transfer_queues[shard_idx].put(
        TransferEmbeddingChunk(
            room=bootstrap_room,
            embedding_indices=embedding_indices,
            is_last=is_last,
            total_tokens=total_tokens,
        )
    )
```

---

## ğŸ“Š å®Œæ•´æµç¨‹ç¤ºä¾‹

### åœºæ™¯ï¼šå®é™…2000 tokensï¼ŒLanguageé¦–æ¬¡åˆ†é…1024 tokens

```
æ—¶é—´çº¿:

T0: Languageä¾§
    â””â”€ åˆ†é…8 blocks (1024 tokens)
    â””â”€ init(embedding_indices=[0,1,2,3,4,5,6,7], allocated_tokens=1024)
    â””â”€ Status: Bootstrapping -> WaitingForInput

T1: Embeddingä¾§
    â””â”€ æ¥æ”¶åˆ°initè¯·æ±‚
    â””â”€ actual_length = 2000 tokens
    â””â”€ åˆ†é…16 blocks (2000 tokens)
    â””â”€ åˆ¤æ–­: is_last = (2000 <= 1024) = False
    â””â”€ send_embedding(tokens=1024, is_last=False, sent_tokens=0)

T2: ç¬¬ä¸€æ¬¡ä¼ è¾“
    â””â”€ Embedding -> Language: 1024 tokens
    â””â”€ Status: WaitingForInput -> Transferring
    â””â”€ aux_datas[0] = 2000 (å®é™…æ€»é•¿åº¦)

T3: Languageä¾§æ£€æµ‹åˆ°éƒ¨åˆ†ä¼ è¾“
    â””â”€ poll() = Transferring
    â””â”€ è¯»å–aux_datas: actual_total_length = 2000
    â””â”€ è®¡ç®—: remaining = 2000 - 1024 = 976 tokens
    â””â”€ ç¼“å­˜å·²æ¥æ”¶çš„1024 tokens
    â””â”€ é‡Šæ”¾æ—§åˆ†é…çš„8 blocks
    â””â”€ é‡æ–°åˆ†é…8 blocks (976 tokens)

T4: Languageä¾§å‘é€Resumeè¯·æ±‚
    â””â”€ resume_transfer(
          embedding_indices=[8,9,10,11,12,13,14,15],
          sent_tokens=1024,
          allocated_tokens=976
        )

T5: Embeddingä¾§æ¥æ”¶Resumeè¯·æ±‚
    â””â”€ æ›´æ–°transfer_info:
        - sent_tokens = 1024
        - allocated_tokens = 976
        - dst_embedding_indices = [8,9,10,11,12,13,14,15]
    â””â”€ Statusä¿æŒ: Transferring (ä¸é‡ç½®)

T6: Embeddingä¾§ç»§ç»­ä¼ è¾“
    â””â”€ åˆ¤æ–­: is_last = (976 <= 976) = True
    â””â”€ send_embedding(
          tokens=976,
          is_last=True,
          sent_tokens=1024
        )

T7: ç¬¬äºŒæ¬¡ä¼ è¾“
    â””â”€ Embedding -> Language: 976 tokens (ä»offset 1024å¼€å§‹)
    â””â”€ Status: Transferring -> Success

T8: Languageä¾§å®Œæˆ
    â””â”€ poll() = Success
    â””â”€ åˆå¹¶æ•°æ®: 1024 + 976 = 2000 tokens âœ…
    â””â”€ å¤„ç†è¯·æ±‚
```

---

## ğŸ”‘ å…³é”®è®¾è®¡è¦ç‚¹

### 1. Statusè½¬æ¢è§„åˆ™
```
å°æ•°æ®ï¼ˆä¸€æ¬¡å®Œæˆï¼‰:
  Bootstrapping -> WaitingForInput -> Success

å¤§æ•°æ®ï¼ˆéœ€è¦Resumeï¼‰:
  Bootstrapping -> WaitingForInput -> Transferring -> Success

å¤±è´¥:
  ä»»æ„çŠ¶æ€ -> Failed
```

### 2. é˜²æ­¢é‡å¤ä¼ è¾“
```python
# ä½¿ç”¨statuså’Œsent_tokensåŒé‡æ£€æŸ¥
if current_status == KVPoll.Transferring and sent_tokens == 0:
    return  # å·²ç»åœ¨ä¼ è¾“ä¸­ï¼Œè·³è¿‡
```

### 3. æ•°æ®ä¸€è‡´æ€§
- aux_datasåœ¨ç¬¬ä¸€æ¬¡ä¼ è¾“æ—¶å‘é€ï¼ŒåŒ…å«å®é™…æ€»é•¿åº¦
- Languageä¾§æ ¹æ®aux_datasåˆ¤æ–­æ˜¯å¦éœ€è¦resume
- ä½¿ç”¨sent_tokensç²¾ç¡®è·Ÿè¸ªè¿›åº¦

### 4. å†…å­˜ç®¡ç†
- Languageä¾§åœ¨resumeå‰é‡Šæ”¾æ—§çš„åˆ†é…
- Embeddingä¾§ä¿æŒtransfer_infosç›´åˆ°å®Œå…¨æˆåŠŸ
- æ”¯æŒç¼“å­˜éƒ¨åˆ†æ•°æ®

---

## ğŸ§ª æµ‹è¯•åœºæ™¯

### 1. å°æ•°æ®ï¼ˆæ— éœ€Resumeï¼‰
```
å®é™…: 500 tokens
é»˜è®¤: 1024 tokens
é¢„æœŸ: ä¸€æ¬¡ä¼ è¾“å®Œæˆï¼ŒStatus: WaitingForInput -> Success
```

### 2. å¤§æ•°æ®ï¼ˆéœ€è¦Resumeï¼‰
```
å®é™…: 2000 tokens
é»˜è®¤: 1024 tokens
é¢„æœŸ: ä¸¤æ¬¡ä¼ è¾“ï¼ŒStatus: WaitingForInput -> Transferring -> Success
```

### 3. æç«¯æƒ…å†µ
```
å®é™…: 10000 tokens
é»˜è®¤: 1024 tokens
é¢„æœŸ: å¤šæ¬¡Resume? (å–å†³äºå®ç°ï¼Œå»ºè®®å•æ¬¡Resume)
```

### 4. å¤±è´¥åœºæ™¯
```
- Resumeæ—¶å†…å­˜ä¸è¶³
- ä¼ è¾“ä¸­æ–­
- Sessionå¤±æ•ˆ
é¢„æœŸ: Status -> Failedï¼Œæ¸…ç†èµ„æº
```

---

## ğŸ“ å®ç°è®¡åˆ’

### Phase 1: æ ¸å¿ƒæ•°æ®ç»“æ„å’Œæ¶ˆæ¯åè®®
1. âœ… `TransferEmbeddingInfo`æ·»åŠ `sent_tokens`å’Œ`allocated_tokens`å­—æ®µ
2. âœ… ä¿®æ”¹ZMQæ¶ˆæ¯æ ¼å¼æ”¯æŒresumeï¼ˆåŒºåˆ†initå’Œresumeæ¶ˆæ¯ï¼‰
3. âœ… ä¿®æ”¹`TransferEmbeddingInfo.from_zmq()`è§£ææ–°å­—æ®µ

### Phase 2: Connectionå±‚å®ç°
1. âœ… ä¿®æ”¹`send_embedding()`æ–¹æ³•
   - æ·»åŠ `allocated_tokens`å‚æ•°
   - åŸºäºtokensè€Œéblocksåˆ¤æ–­
   - æ ¡éªŒblock_sizeä¸€è‡´æ€§
   - è¿”å›`(ret, is_partial)`
2. âœ… ä¿®æ”¹`embedding_thread()`å¤„ç†resumeæ¶ˆæ¯
3. âœ… ä¿®æ”¹`transfer_worker()`æ ¹æ®`is_partial`è®¾ç½®status
4. âœ… æ·»åŠ é˜²æ­¢é‡å¤ä¼ è¾“æ£€æŸ¥

### Phase 3: Languageä¾§å®ç°
1. âœ… `MooncakeEmbeddingReceiver.init()`æ·»åŠ `allocated_tokens`å‚æ•°
2. âœ… æ–°å¢`MooncakeEmbeddingReceiver.resume_transfer()`æ–¹æ³•
3. âœ… ä¿®æ”¹`MultimodalLanguageTransferQueue.pop_transferred()`
   - æ£€æµ‹`KVPoll.Transferring`çŠ¶æ€
   - å®ç°éƒ¨åˆ†æ•°æ®ç¼“å­˜
   - è§¦å‘resumeä¼ è¾“
   - å®ç°æ•°æ®åˆå¹¶é€»è¾‘

### Phase 4: Embeddingä¾§é€‚é…ï¼ˆæœ€å°ä¿®æ”¹ï¼‰
1. âœ… ç¡®è®¤`send_embedding_chunk()`ä¿æŒä¸å˜
2. âœ… ç¡®è®¤`MooncakeEmbeddingSender.send_embedding()`åªåœ¨é¦–æ¬¡è°ƒç”¨

### Phase 5: æµ‹è¯•å’Œæ–‡æ¡£
1. ğŸ”„ å•å…ƒæµ‹è¯•ï¼šå°æ•°æ®ï¼ˆæ— Resumeï¼‰
2. ğŸ”„ å•å…ƒæµ‹è¯•ï¼šå¤§æ•°æ®ï¼ˆå•æ¬¡Resumeï¼‰
3. ğŸ”„ é›†æˆæµ‹è¯•ï¼šå®é™…æ¨¡å‹åœºæ™¯
4. ğŸ”„ é”™è¯¯åœºæ™¯æµ‹è¯•ï¼šå†…å­˜ä¸è¶³ã€ä¼ è¾“å¤±è´¥
5. ğŸ”„ æ›´æ–°ç”¨æˆ·æ–‡æ¡£å’Œé…ç½®è¯´æ˜

---

## â“ è®¨è®ºé—®é¢˜ä¸å†³ç­–

### âœ… å·²ç¡®è®¤çš„è®¾è®¡å†³ç­–

1. **æ”¯æŒå•æ¬¡Resumeï¼Œæ¥å£é¢„ç•™å¤šæ¬¡Resumeèƒ½åŠ›**
   - å½“å‰å®ç°ï¼šå•æ¬¡Resumeï¼ˆä¸¤é˜¶æ®µä¼ è¾“ï¼‰
   - æ¥å£è®¾è®¡ï¼šæ”¯æŒsent_tokensè¿½è¸ªï¼Œå¯æ‰©å±•ä¸ºå¤šæ¬¡Resume
   - ç†ç”±ï¼šç®€åŒ–å®ç°ï¼Œæ»¡è¶³å¤§éƒ¨åˆ†åœºæ™¯ï¼›ä¸ºbufferä¸è¶³æƒ…å†µé¢„ç•™æ‰©å±•æ€§

2. **åŸºäºallocated_tokensåˆ¤æ–­ï¼Œè€Œéblockæ•°é‡**
   - ä½¿ç”¨`allocated_tokens`å’Œ`total_tokens`æ¯”è¾ƒ
   - æ ¡éªŒblock_sizeä¸€è‡´æ€§ï¼ˆallocated_tokens / block_num == block_sizeï¼‰
   - æ”¯æŒæœªæ¥ä¸åŒblock_sizeçš„æ‰©å±•

3. **last_chunkä¸æ··ç”¨**
   - `last_chunk`ä»…ç”¨äºchunk-prefill
   - Resumeä¼ è¾“ç”±`is_partial`æ ‡å¿—æ§åˆ¶
   - `send_embedding_chunk()`åªåœ¨é¦–æ¬¡è°ƒç”¨ï¼Œä¸å‚ä¸resumeæµç¨‹

4. **ç§»é™¤æœªä½¿ç”¨çš„resume_queue**
   - Resumeé€»è¾‘åœ¨`MultimodalLanguageTransferQueue.pop_transferred()`ä¸­å¤„ç†
   - ä¸éœ€è¦å•ç‹¬çš„é˜Ÿåˆ—

### ğŸ”„ å¾…è®¨è®ºçš„é—®é¢˜

1. **é»˜è®¤bufferå¤§å°ç­–ç•¥**
   - å½“å‰ï¼šå›ºå®š8192 tokens
   - è€ƒè™‘ï¼šæ˜¯å¦éœ€è¦æ ¹æ®æ¨¡å‹æˆ–å†å²è¯·æ±‚åŠ¨æ€è°ƒæ•´ï¼Ÿ

2. **Resumeæ—¶å†…å­˜ä¸è¶³çš„å¤„ç†**
   - æ–¹æ¡ˆAï¼šç­‰å¾…é‡Šæ”¾åé‡è¯•ï¼ˆéœ€è¦é‡è¯•é˜Ÿåˆ—ï¼‰
   - æ–¹æ¡ˆBï¼šç«‹å³å¤±è´¥ï¼ˆç®€å•ä½†å¯èƒ½å½±å“æˆåŠŸç‡ï¼‰
   - æ–¹æ¡ˆCï¼šé™çº§åˆ°æ›´å°çš„åˆ†é…ï¼ˆå¤æ‚ï¼Œæ”¯æŒå¤šæ¬¡Resumeï¼‰
   
   **å»ºè®®**ï¼šå…ˆå®ç°æ–¹æ¡ˆBï¼ˆç«‹å³å¤±è´¥ï¼‰ï¼Œåç»­å¯å‡çº§åˆ°æ–¹æ¡ˆA

---

## ğŸ”§ å…³é”®ä¿®æ­£æ€»ç»“

æ ¹æ®åé¦ˆï¼Œå·²å®Œæˆä»¥ä¸‹å…³é”®ä¿®æ­£ï¼š

### 1. âœ… ç§»é™¤æœªä½¿ç”¨çš„resume_queue
- Resumeé€»è¾‘ç›´æ¥åœ¨`MultimodalLanguageTransferQueue.pop_transferred()`ä¸­å¤„ç†
- ä¸éœ€è¦é¢å¤–çš„é˜Ÿåˆ—

### 2. âœ… æ¾„æ¸…last_chunkçš„ç”¨é€”
- `last_chunk`ä»…ç”¨äºchunk-prefillï¼Œä¸ä¸chunk-transferæ··ç”¨
- `send_embedding_chunk()`åªåœ¨é¦–æ¬¡è°ƒç”¨ï¼Œä¸å‚ä¸resumeæµç¨‹
- Resumeç”±Connectionå±‚çš„`is_partial`æ ‡å¿—æ§åˆ¶

### 3. âœ… åŸºäºallocated_tokensåˆ¤æ–­
- ä¿®æ”¹bufferéªŒè¯é€»è¾‘ï¼šä½¿ç”¨`allocated_tokens`è€Œé`len(embedding_indices)`
- æ·»åŠ block_sizeä¸€è‡´æ€§æ ¡éªŒ
- æ”¯æŒä¸åŒblock_sizeçš„æ‰©å±•ï¼ˆè™½ç„¶å½“å‰é»˜è®¤ä¸€è‡´ï¼‰

### 4. âœ… å•æ¬¡Resume + æ‰©å±•æ¥å£
- å½“å‰å®ç°ï¼šå•æ¬¡Resumeï¼ˆä¸¤é˜¶æ®µä¼ è¾“ï¼‰
- æ¥å£è®¾è®¡ï¼šæ”¯æŒ`sent_tokens`è¿½è¸ªï¼Œé¢„ç•™å¤šæ¬¡Resumeèƒ½åŠ›
- ä¸ºbufferä¸è¶³åœºæ™¯é¢„ç•™æ‰©å±•æ€§

## ğŸ¯ ä¸‹ä¸€æ­¥

è®¾è®¡æ–¹æ¡ˆå·²æ ¹æ®åé¦ˆå®Œæˆä¿®æ­£ï¼Œè¯·ç¡®è®¤ï¼š
1. âœ… Resumeæœºåˆ¶æ˜¯å¦ç¬¦åˆé¢„æœŸï¼Ÿ
2. âœ… last_chunkå’Œis_partialçš„åŒºåˆ†æ˜¯å¦æ¸…æ™°ï¼Ÿ
3. âœ… åŸºäºallocated_tokensçš„éªŒè¯é€»è¾‘æ˜¯å¦æ­£ç¡®ï¼Ÿ
4. âœ… æ¥å£è®¾è®¡æ˜¯å¦æ”¯æŒæœªæ¥æ‰©å±•ï¼Ÿ

**ç¡®è®¤åå³å¯å¼€å§‹å®ç°ä»£ç **ã€‚
