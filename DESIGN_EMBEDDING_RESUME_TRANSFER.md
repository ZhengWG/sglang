# å¤šæ¨¡æ€Embedding Resumeä¼ è¾“è®¾è®¡æ–¹æ¡ˆ

## ğŸ“‹ é—®é¢˜æè¿°

### å½“å‰é—®é¢˜
Languageä¾§æ¯æ¬¡ç”³è¯·blockæ˜¯æŒ‰ç…§**é»˜è®¤å€¼**ç”³è¯·çš„ï¼ˆç›®å‰æ˜¯8192 tokensï¼‰ï¼Œä½†Embeddingä¾§èƒ½è·å–**å®é™…çš„req_len**ï¼Œè¿™å¯¼è‡´`dst_embedding_indices`æ•°ç›®å¯èƒ½ä¼š**å°äº**Embeddingä¾§`embedding_indices`æ•°ç›®ã€‚

### ç¤ºä¾‹åœºæ™¯
```
å®é™…æƒ…å†µ: Embeddingä¾§éœ€è¦å‘é€2000 tokensçš„æ•°æ®
Languageä¾§: é»˜è®¤åˆ†é…1024 tokens (8 blocks * 128 tokens/block)
é—®é¢˜: 1024 < 2000ï¼Œç›®æ ‡ç¼“å†²åŒºä¸è¶³
```

å½“å‰è¡Œä¸ºï¼ˆ`conn_multimodal.py` 233-238è¡Œï¼‰:
```python
if len(embedding_indices) > len(dst_embedding_indices):
    raise ValueError(
        f"Source blocks ({len(embedding_indices)}) cannot be greater than "
        f"destination blocks ({len(dst_embedding_indices)}). "
        f"Language side allocated insufficient buffer."
    )
```

---

## ğŸ¯ è§£å†³æ–¹æ¡ˆï¼šResumeä¼ è¾“æœºåˆ¶

### æ ¸å¿ƒæ€è·¯
å®ç°**ä¸¤é˜¶æ®µä¼ è¾“**æœºåˆ¶ï¼š
1. **ç¬¬ä¸€é˜¶æ®µ**: Languageä¾§æŒ‰é»˜è®¤å€¼åˆ†é… â†’ Embeddingä¾§å‘é€éƒ¨åˆ†æ•°æ®
2. **é€šçŸ¥é˜¶æ®µ**: Embeddingä¾§å‘ŠçŸ¥Languageå®é™…é•¿åº¦
3. **ç¬¬äºŒé˜¶æ®µ**: Languageä¾§é‡æ–°åˆ†é…å‰©ä½™ç©ºé—´ â†’ Embeddingä¾§å‘é€å‰©ä½™æ•°æ®

---

## ğŸ—ï¸ è®¾è®¡æ–¹æ¡ˆ

### 1. æ•°æ®ç»“æ„ä¿®æ”¹

#### 1.1 `TransferEmbeddingInfo` (conn_multimodal.py)
æ·»åŠ å­—æ®µè·Ÿè¸ªä¼ è¾“è¿›åº¦ï¼š

```python
@dataclasses.dataclass
class TransferEmbeddingInfo:
    room: int
    endpoint: str
    dst_port: int
    mooncake_session_id: str
    dst_embedding_indices: List[int]
    required_dst_info_num: int
    sent_tokens: int = 0           # æ–°å¢ï¼šå·²å‘é€çš„tokenæ•°
    allocated_tokens: int = 0      # æ–°å¢ï¼šLanguageä¾§åˆ†é…çš„tokenæ•°
```

#### 1.2 Resumeè¯·æ±‚æ¶ˆæ¯æ ¼å¼
åœ¨ZMQæ¶ˆæ¯ä¸­æ·»åŠ resumeä¿¡æ¯ï¼š

```python
# åˆå§‹åŒ–æ¶ˆæ¯ï¼ˆinitï¼‰
[
    str(room).encode("ascii"),
    endpoint.encode("ascii"),
    str(dst_port).encode("ascii"),
    session_id.encode("ascii"),
    embedding_indices_str.encode("ascii"),
    str(required_dst_info_num).encode("ascii"),
    str(allocated_tokens).encode("ascii"),  # æ–°å¢
]

# Resumeæ¶ˆæ¯ï¼ˆresume_transferï¼‰
[
    str(room).encode("ascii"),
    endpoint.encode("ascii"),
    str(dst_port).encode("ascii"),
    session_id.encode("ascii"),
    embedding_indices_str.encode("ascii"),
    str(required_dst_info_num).encode("ascii"),
    str(sent_tokens).encode("ascii"),       # æ–°å¢ï¼šå·²å‘é€çš„tokenæ•°
    str(allocated_tokens).encode("ascii"),  # æ–°å¢ï¼šæ–°åˆ†é…çš„tokenæ•°
]
```

---

### 2. Languageä¾§ä¿®æ”¹ (multimodal_language.py)

#### 2.1 åœ¨`MultimodalLanguagePreallocQueue`ä¸­æ·»åŠ Resumeé€»è¾‘

```python
class MultimodalLanguagePreallocQueue:
    def __init__(self, ...):
        # ç°æœ‰ä»£ç ...
        self.default_allocate_tokens = int(
            os.getenv("SGLANG_EMBEDDING_DEFAULT_ALLOCATE_BUFFER_SIZE", "8192")
        )
        # æ–°å¢ï¼šè·Ÿè¸ªéœ€è¦resumeçš„è¯·æ±‚
        self.resume_queue: List[MultimodalLanguageRequest] = []
```

#### 2.2 ä¿®æ”¹`MooncakeEmbeddingReceiver.init()`æ–¹æ³•

æ·»åŠ `allocated_tokens`å‚æ•°ï¼š
```python
def init(
    self,
    embedding_indices: Optional[List[int]] = None,
    allocated_tokens: Optional[int] = None,  # æ–°å¢
):
    if embedding_indices is not None:
        embedding_indices_str = ",".join(str(idx) for idx in embedding_indices)
    else:
        embedding_indices_str = ""
    
    # è®¡ç®—allocated_tokens
    if allocated_tokens is None:
        block_size = self.embedding_mgr.data_args.aux_item_lens[1] // 4
        allocated_tokens = len(embedding_indices) * block_size
    
    for bootstrap_info in self.bootstrap_infos:
        # ...å‘é€æ¶ˆæ¯ï¼ŒåŒ…å«allocated_tokens
        sock.send_multipart([
            str(self.bootstrap_room).encode("ascii"),
            get_local_ip_by_remote().encode("ascii"),
            str(self.embedding_mgr.rank_port).encode("ascii"),
            self.session_id.encode("ascii"),
            embedding_indices_str.encode("ascii"),
            str(self.required_dst_info_num).encode("ascii"),
            str(allocated_tokens).encode("ascii"),  # æ–°å¢
        ])
```

#### 2.3 æ·»åŠ Resumeä¼ è¾“æ–¹æ³•

```python
class MooncakeEmbeddingReceiver(BaseKVReceiver):
    def resume_transfer(
        self,
        embedding_indices: List[int],
        sent_tokens: int,
        allocated_tokens: int,
    ):
        """Resume transfer with new allocation after partial transfer.
        
        Args:
            embedding_indices: New block allocation for remaining data
            sent_tokens: Number of tokens already transferred
            allocated_tokens: Number of tokens in new allocation
        """
        embedding_indices_str = ",".join(str(idx) for idx in embedding_indices)
        
        for bootstrap_info in self.bootstrap_infos:
            self.embedding_server_url = (
                f"{bootstrap_info['rank_ip']}:{bootstrap_info['rank_port']}"
            )
            
            sock, lock = self._connect("tcp://" + self.embedding_server_url)
            with lock:
                sock.send_multipart([
                    str(self.bootstrap_room).encode("ascii"),
                    get_local_ip_by_remote().encode("ascii"),
                    str(self.embedding_mgr.rank_port).encode("ascii"),
                    self.session_id.encode("ascii"),
                    embedding_indices_str.encode("ascii"),
                    str(self.required_dst_info_num).encode("ascii"),
                    str(sent_tokens).encode("ascii"),      # æ ‡è¯†resume
                    str(allocated_tokens).encode("ascii"),  # æ–°åˆ†é…çš„å¤§å°
                ])
```

#### 2.4 ä¿®æ”¹`MultimodalLanguageTransferQueue.pop_transferred()`

æ£€æµ‹éƒ¨åˆ†ä¼ è¾“ï¼Œå¹¶è§¦å‘resumeï¼š
```python
def pop_transferred(self):
    # ...ç°æœ‰ä»£ç ...
    
    for i, (language_req, poll) in enumerate(zip(self.queue, polls)):
        if poll == KVPoll.Transferring:  # æ–°çŠ¶æ€ï¼šéƒ¨åˆ†ä¼ è¾“å®Œæˆ
            # è·å–å®é™…éœ€è¦çš„æ€»é•¿åº¦
            block_indices = language_req.embedding_indices
            embedding_data, fill_ids, mrope_positions, aux_datas = (
                self.metadata_buffers.get_buf(block_indices=block_indices)
            )
            actual_total_length = aux_datas[0]  # å®é™…æ€»é•¿åº¦
            sent_tokens = len(fill_ids)          # å·²å‘é€çš„tokenæ•°
            
            if actual_total_length > sent_tokens:
                # éœ€è¦resumeä¼ è¾“
                remaining_tokens = actual_total_length - sent_tokens
                
                # ç¼“å­˜å·²æ¥æ”¶çš„æ•°æ®
                language_req.req.partial_input_embeds = embedding_data
                language_req.req.partial_fill_ids = fill_ids.tolist()
                language_req.req.partial_mrope_positions = mrope_positions
                language_req.req.partial_aux_datas = aux_datas
                
                # é‡Šæ”¾æ—§çš„åˆ†é…
                self.req_to_metadata_buffer_idx_allocator.free(
                    block_indices=block_indices,
                    req_id=language_req.req.rid,
                    fake=isinstance(language_req.embedding_receiver, FakeKVReceiver),
                )
                
                # é‡æ–°åˆ†é…å‰©ä½™ç©ºé—´
                new_allocation = self.req_to_metadata_buffer_idx_allocator.alloc(
                    num_tokens=remaining_tokens,
                    req_id=language_req.req.rid,
                    fake=isinstance(language_req.embedding_receiver, FakeKVReceiver),
                )
                
                if new_allocation is None:
                    # å†…å­˜ä¸è¶³ï¼Œç¨åé‡è¯•
                    logger.warning(f"Not enough memory to resume transfer for {language_req.req.rid}")
                    continue
                
                # æ›´æ–°embedding_indices
                language_req.embedding_indices = new_allocation
                
                # å‘é€resumeè¯·æ±‚
                language_req.embedding_receiver.resume_transfer(
                    embedding_indices=new_allocation,
                    sent_tokens=sent_tokens,
                    allocated_tokens=remaining_tokens,
                )
                
                # ç»§ç»­ç­‰å¾…
                continue
        
        elif poll == KVPoll.Success:
            # å®Œæ•´ä¼ è¾“å®Œæˆ
            # å¦‚æœæœ‰partialæ•°æ®ï¼Œéœ€è¦åˆå¹¶
            if hasattr(language_req.req, 'partial_input_embeds'):
                # åˆå¹¶æ•°æ®
                new_embedding_data, new_fill_ids, new_mrope_positions, _ = (
                    self.metadata_buffers.get_buf(block_indices=language_req.embedding_indices)
                )
                
                language_req.req.input_embeds = torch.cat([
                    language_req.req.partial_input_embeds,
                    new_embedding_data
                ])
                language_req.req.origin_input_ids = (
                    language_req.req.partial_fill_ids + new_fill_ids.tolist()
                )
                # åˆå¹¶mrope_positions...
                
                # æ¸…ç†partialæ•°æ®
                del language_req.req.partial_input_embeds
                del language_req.req.partial_fill_ids
                del language_req.req.partial_mrope_positions
                del language_req.req.partial_aux_datas
            else:
                # æ­£å¸¸å•æ¬¡ä¼ è¾“å®Œæˆ
                # ...ç°æœ‰ä»£ç ...
            
            transferred_reqs.append(language_req.req)
            indices_to_remove.add(i)
```

---

### 3. Embeddingä¾§ä¿®æ”¹ (multimodal_embedding.py)

#### 3.1 ä¿®æ”¹`send_embedding_chunk()`

æ·»åŠ `sent_tokens`å‚æ•°æ”¯æŒresumeï¼š
```python
def send_embedding_chunk(
    self: Scheduler,
    req: Req,
    last_chunk: bool = False,
    sent_tokens: int = 0,  # æ–°å¢ï¼šå·²å‘é€çš„tokenæ•°
):
    assert last_chunk == True or sent_tokens > 0  # è¦ä¹ˆæ˜¯æœ€åä¸€å—ï¼Œè¦ä¹ˆæ˜¯resume
    
    if last_chunk and sent_tokens == 0:
        # åˆæ¬¡ä¼ è¾“
        self.disagg_metadata_buffers.set_buf(req)
    
    # è®¡ç®—è¦å‘é€çš„indicesï¼ˆè·³è¿‡å·²å‘é€çš„éƒ¨åˆ†ï¼‰
    total_tokens = len(req.fill_ids)
    remaining_tokens = total_tokens - sent_tokens
    
    # Send using block_indices
    req.disagg_embedding_sender.send_embedding(
        embedding_indices=req.embedding_indices,
        last_chunk=last_chunk,
        total_tokens=remaining_tokens,
        sent_tokens=sent_tokens,
        block_size=self.disagg_metadata_buffers.block_size,
    )
```

#### 3.2 ä¿®æ”¹`MooncakeEmbeddingSender`

æ·»åŠ resumeæ”¯æŒï¼š
```python
class MooncakeEmbeddingSender(BaseKVSender):
    def __init__(self, ...):
        # ...ç°æœ‰ä»£ç ...
        self.sent_tokens = 0  # æ–°å¢ï¼šè·Ÿè¸ªå·²å‘é€çš„tokenæ•°
    
    def send_embedding(
        self,
        embedding_indices: List[int] = None,
        last_chunk: bool = True,
        total_tokens: int = None,
        block_size: int = None,
        sent_tokens: int = 0,  # æ–°å¢
    ):
        """Send embedding data to language instances using block-based transfer.
        
        Args:
            embedding_indices: List of source embedding indices
            last_chunk: Whether this is the last chunk
            total_tokens: Total number of tokens to transfer (excluding sent_tokens)
            block_size: Number of tokens per block
            sent_tokens: Number of tokens already sent (for resume)
        """
        self.sent_tokens = sent_tokens
        self.embedding_mgr.add_transfer_request(
            self.bootstrap_room,
            embedding_indices,
            last_chunk,
            total_tokens,
            block_size,
            sent_tokens,
        )
```

---

### 4. Connectionå±‚ä¿®æ”¹ (conn_multimodal.py)

#### 4.1 ä¿®æ”¹`send_embedding()`æ–¹æ³•

æ”¯æŒéƒ¨åˆ†ä¼ è¾“ï¼š
```python
def send_embedding(
    self,
    mooncake_session_id: str,
    embedding_indices: List[int],
    dst_embedding_ptrs: list[int],
    dst_embedding_indices: List[int],
    total_tokens: int,
    block_size: int,
    sent_tokens: int = 0,  # æ–°å¢ï¼šå·²å‘é€çš„tokenæ•°
):
    """Send embedding data using block-based transfer.
    
    Args:
        sent_tokens: Number of tokens already sent (for resume transfer)
    """
    # Validate: ç§»é™¤ä¸¥æ ¼çš„éªŒè¯ï¼Œå…è®¸éƒ¨åˆ†ä¼ è¾“
    if sent_tokens == 0 and len(embedding_indices) > len(dst_embedding_indices):
        # åˆæ¬¡ä¼ è¾“ä¸”ç¼“å†²åŒºä¸è¶³ï¼šåªå‘é€éƒ¨åˆ†
        logger.warning(
            f"Partial transfer: Source blocks ({len(embedding_indices)}) > "
            f"destination blocks ({len(dst_embedding_indices)}). "
            f"Will transfer {len(dst_embedding_indices)} blocks first."
        )
        # åªä¼ è¾“èƒ½å®¹çº³çš„éƒ¨åˆ†
        tokens_to_send = len(dst_embedding_indices) * block_size
        total_tokens = min(total_tokens, tokens_to_send)
    
    # è®¡ç®—è¦å‘é€çš„blockèŒƒå›´
    start_block = sent_tokens // block_size
    embedding_indices_to_send = embedding_indices[start_block:]
    
    # é™åˆ¶ä¸ºdstå®¹é‡
    if len(embedding_indices_to_send) > len(dst_embedding_indices):
        embedding_indices_to_send = embedding_indices_to_send[:len(dst_embedding_indices)]
    
    src_addrs = []
    dst_addrs = []
    lengths = []
    
    for block_idx, (src_block_idx, dst_block_idx) in enumerate(
        zip(embedding_indices_to_send, dst_embedding_indices)
    ):
        # Calculate tokens in this block
        tokens_in_prev_blocks = start_block * block_size + block_idx * block_size
        start_pos = tokens_in_prev_blocks - sent_tokens
        end_pos = min(start_pos + block_size, total_tokens)
        tokens_in_block = end_pos - start_pos
        
        if tokens_in_block <= 0:
            break
        
        # Transfer each buffer type within the block
        for buffer_type_idx in range(len(self.data_args.aux_item_lens)):
            embedding_item_len = self.data_args.aux_item_lens[buffer_type_idx]
            
            # Calculate chunk size
            if buffer_type_idx == 3:  # aux_datas
                if sent_tokens == 0 and block_idx == 0:  # åªåœ¨åˆæ¬¡ä¼ è¾“çš„ç¬¬ä¸€ä¸ªå—å‘é€
                    chunk_size = embedding_item_len
                else:
                    continue
            else:
                chunk_size = (embedding_item_len * tokens_in_block) // block_size
            
            embedding_addr = (
                self.data_args.aux_data_ptrs[buffer_type_idx]
                + src_block_idx * embedding_item_len
            )
            dst_embedding_addr = (
                dst_embedding_ptrs[buffer_type_idx]
                + dst_block_idx * embedding_item_len
            )
            
            src_addrs.append(embedding_addr)
            dst_addrs.append(dst_embedding_addr)
            lengths.append(chunk_size)
    
    return self.engine.batch_transfer_sync(
        mooncake_session_id, src_addrs, dst_addrs, lengths
    )
```

#### 4.2 ä¿®æ”¹`embedding_thread()`å¤„ç†Resumeæ¶ˆæ¯

```python
def embedding_thread():
    """This thread recvs pre-alloc notification from the language engine"""
    while True:
        waiting_req_bytes = self.server_socket.recv_multipart()
        room = waiting_req_bytes[0].decode("ascii")
        mooncake_session_id = waiting_req_bytes[3].decode("ascii")
        
        if room == "None":
            # æ³¨å†Œè¯·æ±‚
            self.language_args_table[mooncake_session_id] = (
                EmbeddingArgsRegisterInfo.from_zmq(waiting_req_bytes)
            )
            # ...ç°æœ‰ä»£ç ...
        else:
            room = int(room)
            
            # è§£ææ¶ˆæ¯
            dst_embedding_indices_str = waiting_req_bytes[4].decode("ascii")
            dst_embedding_indices = (
                [int(x) for x in dst_embedding_indices_str.split(",")]
                if dst_embedding_indices_str else []
            )
            required_dst_info_num = int(waiting_req_bytes[5].decode("ascii"))
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯resumeè¯·æ±‚ï¼ˆ7ä¸ªå­—æ®µï¼‰
            is_resume = len(waiting_req_bytes) >= 8
            
            if is_resume:
                # Resumeè¯·æ±‚
                sent_tokens = int(waiting_req_bytes[6].decode("ascii"))
                allocated_tokens = int(waiting_req_bytes[7].decode("ascii"))
                
                # æ›´æ–°ç°æœ‰transfer_info
                if room in self.transfer_infos and mooncake_session_id in self.transfer_infos[room]:
                    transfer_info = self.transfer_infos[room][mooncake_session_id]
                    transfer_info.sent_tokens = sent_tokens
                    transfer_info.allocated_tokens = allocated_tokens
                    transfer_info.dst_embedding_indices = dst_embedding_indices
                    
                    # ä¸é‡ç½®statusï¼Œä¿æŒå½“å‰çŠ¶æ€ï¼ˆTransferringï¼‰
                    logger.info(
                        f"Resume transfer for room={room}, sent_tokens={sent_tokens}, "
                        f"allocated_tokens={allocated_tokens}"
                    )
                else:
                    logger.error(f"Cannot resume: room={room} not found in transfer_infos")
            else:
                # åˆæ¬¡è¯·æ±‚
                allocated_tokens = int(waiting_req_bytes[6].decode("ascii"))
                
                if room not in self.transfer_infos:
                    self.transfer_infos[room] = {}
                
                self.transfer_infos[room][mooncake_session_id] = TransferEmbeddingInfo(
                    room=room,
                    endpoint=waiting_req_bytes[1].decode("ascii"),
                    dst_port=int(waiting_req_bytes[2].decode("ascii")),
                    mooncake_session_id=mooncake_session_id,
                    dst_embedding_indices=dst_embedding_indices,
                    required_dst_info_num=required_dst_info_num,
                    sent_tokens=0,
                    allocated_tokens=allocated_tokens,
                )
                
                # æ ‡è®°ä¸ºWaitingForInput
                if len(self.transfer_infos[room]) == required_dst_info_num:
                    self.update_status(room, KVPoll.WaitingForInput)
```

#### 4.3 ä¿®æ”¹`transfer_worker()`åˆ¤æ–­æ˜¯å¦å®Œæ•´ä¼ è¾“

```python
def transfer_worker(self, queue: FastQueue, executor: concurrent.futures.ThreadPoolExecutor):
    while True:
        try:
            embedding_chunk: TransferEmbeddingChunk = queue.get()
            # ...ç°æœ‰ä»£ç ...
            
            for req in reqs_to_be_processed:
                # è·å–allocated_tokens
                allocated_tokens = req.allocated_tokens
                sent_tokens = req.sent_tokens
                
                # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€åä¸€æ¬¡ä¼ è¾“
                remaining_tokens = embedding_chunk.total_tokens - sent_tokens
                is_last = (remaining_tokens <= allocated_tokens)
                
                # è®¡ç®—å®é™…è¦å‘é€çš„tokenæ•°
                tokens_to_send = min(remaining_tokens, allocated_tokens)
                
                block_size = self.data_args.aux_item_lens[1] // 4
                
                ret = self.send_embedding(
                    req.mooncake_session_id,
                    embedding_chunk.embedding_indices,
                    self.language_args_table[req.mooncake_session_id].dst_embedding_ptrs,
                    req.dst_embedding_indices,
                    tokens_to_send,  # ä½¿ç”¨è®¡ç®—çš„tokenæ•°
                    block_size,
                    sent_tokens,     # ä¼ é€’å·²å‘é€çš„tokenæ•°
                )
                
                if ret != 0:
                    # ...é”™è¯¯å¤„ç†...
                    break
                
                # æ›´æ–°sent_tokens
                req.sent_tokens += tokens_to_send
                
                polls.append(True)
                dst_ranks_infos.append((req.endpoint, req.dst_port, req.room))
                
                # æ ¹æ®is_lastè®¾ç½®çŠ¶æ€
                if len(polls) == req.required_dst_info_num:
                    if is_last:
                        # å®Œæ•´ä¼ è¾“å®Œæˆ
                        status = KVPoll.Success if all(polls) else KVPoll.Failed
                    else:
                        # éƒ¨åˆ†ä¼ è¾“å®Œæˆï¼Œç­‰å¾…resume
                        status = KVPoll.Transferring if all(polls) else KVPoll.Failed
                    
                    self.update_status(req.room, status)
                    
                    for endpoint, dst_port, room in dst_ranks_infos:
                        self.sync_status_to_language_endpoint(
                            endpoint, dst_port, room, status
                        )
            
            # åªæœ‰å®Œå…¨æˆåŠŸæ—¶æ‰æ¸…ç†transfer_infos
            if (
                embedding_chunk.room in self.request_status
                and self.check_status(embedding_chunk.room) == KVPoll.Success
            ):
                if embedding_chunk.room in self.transfer_infos:
                    self.transfer_infos.pop(embedding_chunk.room)
        
        except Exception as e:
            raise RuntimeError(f"Transfer thread failed: {e}")
```

#### 4.4 æ·»åŠ é˜²æ­¢é‡å¤ä¼ è¾“çš„æ£€æŸ¥

```python
def add_transfer_request(
    self,
    bootstrap_room: int,
    embedding_indices: List[int],
    is_last: bool,
    total_tokens: int,
    block_size: int,
    sent_tokens: int = 0,  # æ–°å¢
):
    """Add block-based transfer request to queue."""
    assert self.disaggregation_mode == DisaggregationMode.ENCODE
    
    if bootstrap_room not in self.request_status or self.check_status(bootstrap_room) == KVPoll.Failed:
        return
    
    if bootstrap_room not in self.transfer_infos:
        return
    
    # é˜²æ­¢é‡å¤ä¼ è¾“ï¼šå¦‚æœstatusæ˜¯Transferringä¸”sent_tokens=0ï¼Œè¯´æ˜å·²ç»åœ¨ä¼ è¾“ä¸­
    current_status = self.check_status(bootstrap_room)
    if current_status == KVPoll.Transferring and sent_tokens == 0:
        logger.debug(f"Skip duplicate transfer for room={bootstrap_room}")
        return
    
    # ...ç°æœ‰ä»£ç ...
    self.transfer_queues[shard_idx].put(
        TransferEmbeddingChunk(
            room=bootstrap_room,
            embedding_indices=embedding_indices,
            is_last=is_last,
            total_tokens=total_tokens,
            sent_tokens=sent_tokens,  # æ–°å¢
        )
    )
```

---

## ğŸ“Š å®Œæ•´æµç¨‹ç¤ºä¾‹

### åœºæ™¯ï¼šå®é™…2000 tokensï¼ŒLanguageé¦–æ¬¡åˆ†é…1024 tokens

```
æ—¶é—´çº¿:

T0: Languageä¾§
    â””â”€ åˆ†é…8 blocks (1024 tokens)
    â””â”€ init(embedding_indices=[0,1,2,3,4,5,6,7], allocated_tokens=1024)
    â””â”€ Status: Bootstrapping -> WaitingForInput

T1: Embeddingä¾§
    â””â”€ æ¥æ”¶åˆ°initè¯·æ±‚
    â””â”€ actual_length = 2000 tokens
    â””â”€ åˆ†é…16 blocks (2000 tokens)
    â””â”€ åˆ¤æ–­: is_last = (2000 <= 1024) = False
    â””â”€ send_embedding(tokens=1024, is_last=False, sent_tokens=0)

T2: ç¬¬ä¸€æ¬¡ä¼ è¾“
    â””â”€ Embedding -> Language: 1024 tokens
    â””â”€ Status: WaitingForInput -> Transferring
    â””â”€ aux_datas[0] = 2000 (å®é™…æ€»é•¿åº¦)

T3: Languageä¾§æ£€æµ‹åˆ°éƒ¨åˆ†ä¼ è¾“
    â””â”€ poll() = Transferring
    â””â”€ è¯»å–aux_datas: actual_total_length = 2000
    â””â”€ è®¡ç®—: remaining = 2000 - 1024 = 976 tokens
    â””â”€ ç¼“å­˜å·²æ¥æ”¶çš„1024 tokens
    â””â”€ é‡Šæ”¾æ—§åˆ†é…çš„8 blocks
    â””â”€ é‡æ–°åˆ†é…8 blocks (976 tokens)

T4: Languageä¾§å‘é€Resumeè¯·æ±‚
    â””â”€ resume_transfer(
          embedding_indices=[8,9,10,11,12,13,14,15],
          sent_tokens=1024,
          allocated_tokens=976
        )

T5: Embeddingä¾§æ¥æ”¶Resumeè¯·æ±‚
    â””â”€ æ›´æ–°transfer_info:
        - sent_tokens = 1024
        - allocated_tokens = 976
        - dst_embedding_indices = [8,9,10,11,12,13,14,15]
    â””â”€ Statusä¿æŒ: Transferring (ä¸é‡ç½®)

T6: Embeddingä¾§ç»§ç»­ä¼ è¾“
    â””â”€ åˆ¤æ–­: is_last = (976 <= 976) = True
    â””â”€ send_embedding(
          tokens=976,
          is_last=True,
          sent_tokens=1024
        )

T7: ç¬¬äºŒæ¬¡ä¼ è¾“
    â””â”€ Embedding -> Language: 976 tokens (ä»offset 1024å¼€å§‹)
    â””â”€ Status: Transferring -> Success

T8: Languageä¾§å®Œæˆ
    â””â”€ poll() = Success
    â””â”€ åˆå¹¶æ•°æ®: 1024 + 976 = 2000 tokens âœ…
    â””â”€ å¤„ç†è¯·æ±‚
```

---

## ğŸ”‘ å…³é”®è®¾è®¡è¦ç‚¹

### 1. Statusè½¬æ¢è§„åˆ™
```
å°æ•°æ®ï¼ˆä¸€æ¬¡å®Œæˆï¼‰:
  Bootstrapping -> WaitingForInput -> Success

å¤§æ•°æ®ï¼ˆéœ€è¦Resumeï¼‰:
  Bootstrapping -> WaitingForInput -> Transferring -> Success

å¤±è´¥:
  ä»»æ„çŠ¶æ€ -> Failed
```

### 2. é˜²æ­¢é‡å¤ä¼ è¾“
```python
# ä½¿ç”¨statuså’Œsent_tokensåŒé‡æ£€æŸ¥
if current_status == KVPoll.Transferring and sent_tokens == 0:
    return  # å·²ç»åœ¨ä¼ è¾“ä¸­ï¼Œè·³è¿‡
```

### 3. æ•°æ®ä¸€è‡´æ€§
- aux_datasåœ¨ç¬¬ä¸€æ¬¡ä¼ è¾“æ—¶å‘é€ï¼ŒåŒ…å«å®é™…æ€»é•¿åº¦
- Languageä¾§æ ¹æ®aux_datasåˆ¤æ–­æ˜¯å¦éœ€è¦resume
- ä½¿ç”¨sent_tokensç²¾ç¡®è·Ÿè¸ªè¿›åº¦

### 4. å†…å­˜ç®¡ç†
- Languageä¾§åœ¨resumeå‰é‡Šæ”¾æ—§çš„åˆ†é…
- Embeddingä¾§ä¿æŒtransfer_infosç›´åˆ°å®Œå…¨æˆåŠŸ
- æ”¯æŒç¼“å­˜éƒ¨åˆ†æ•°æ®

---

## ğŸ§ª æµ‹è¯•åœºæ™¯

### 1. å°æ•°æ®ï¼ˆæ— éœ€Resumeï¼‰
```
å®é™…: 500 tokens
é»˜è®¤: 1024 tokens
é¢„æœŸ: ä¸€æ¬¡ä¼ è¾“å®Œæˆï¼ŒStatus: WaitingForInput -> Success
```

### 2. å¤§æ•°æ®ï¼ˆéœ€è¦Resumeï¼‰
```
å®é™…: 2000 tokens
é»˜è®¤: 1024 tokens
é¢„æœŸ: ä¸¤æ¬¡ä¼ è¾“ï¼ŒStatus: WaitingForInput -> Transferring -> Success
```

### 3. æç«¯æƒ…å†µ
```
å®é™…: 10000 tokens
é»˜è®¤: 1024 tokens
é¢„æœŸ: å¤šæ¬¡Resume? (å–å†³äºå®ç°ï¼Œå»ºè®®å•æ¬¡Resume)
```

### 4. å¤±è´¥åœºæ™¯
```
- Resumeæ—¶å†…å­˜ä¸è¶³
- ä¼ è¾“ä¸­æ–­
- Sessionå¤±æ•ˆ
é¢„æœŸ: Status -> Failedï¼Œæ¸…ç†èµ„æº
```

---

## ğŸ“ å®ç°å»ºè®®

### Phase 1: æ ¸å¿ƒResumeæœºåˆ¶
1. âœ… æ·»åŠ `sent_tokens`å’Œ`allocated_tokens`å­—æ®µ
2. âœ… å®ç°`resume_transfer()`æ–¹æ³•
3. âœ… ä¿®æ”¹æ¶ˆæ¯æ ¼å¼æ”¯æŒresume
4. âœ… ä¿®æ”¹statusè½¬æ¢é€»è¾‘

### Phase 2: æ•°æ®ç®¡ç†
1. âœ… å®ç°éƒ¨åˆ†æ•°æ®ç¼“å­˜
2. âœ… å®ç°æ•°æ®åˆå¹¶é€»è¾‘
3. âœ… æ·»åŠ é˜²æ­¢é‡å¤ä¼ è¾“æ£€æŸ¥

### Phase 3: é”™è¯¯å¤„ç†
1. âœ… Resumeæ—¶å†…å­˜ä¸è¶³å¤„ç†
2. âœ… ä¼ è¾“å¤±è´¥æ¸…ç†
3. âœ… Sessionç®¡ç†

### Phase 4: ä¼˜åŒ–
1. ğŸ”„ è€ƒè™‘æ˜¯å¦æ”¯æŒå¤šæ¬¡Resume
2. ğŸ”„ ä¼˜åŒ–é»˜è®¤bufferå¤§å°ç­–ç•¥
3. ğŸ”„ æ·»åŠ ç›‘æ§å’Œæ—¥å¿—

---

## â“ è®¨è®ºé—®é¢˜

1. **æ˜¯å¦æ”¯æŒå¤šæ¬¡Resume?**
   - å½“å‰è®¾è®¡æ”¯æŒå•æ¬¡Resumeï¼ˆä¸¤é˜¶æ®µä¼ è¾“ï¼‰
   - æ˜¯å¦éœ€è¦æ”¯æŒå¤šæ¬¡Resumeï¼Ÿï¼ˆå¦‚10000 tokensçš„åœºæ™¯ï¼‰

2. **é»˜è®¤bufferå¤§å°ç­–ç•¥**
   - å½“å‰ä½¿ç”¨å›ºå®šçš„8192 tokens
   - æ˜¯å¦éœ€è¦æ ¹æ®å†å²è¯·æ±‚åŠ¨æ€è°ƒæ•´ï¼Ÿ

3. **å†…å­˜ä¸è¶³æ—¶çš„å¤„ç†**
   - Resumeæ—¶å¦‚æœå†…å­˜ä¸è¶³ï¼Œæ˜¯å¦åº”è¯¥ï¼š
     a) ç­‰å¾…é‡Šæ”¾åé‡è¯•
     b) ç«‹å³å¤±è´¥
     c) é™çº§åˆ°æ›´å°çš„åˆ†é…

4. **æ€§èƒ½ä¼˜åŒ–**
   - æ˜¯å¦éœ€è¦é¢„åˆ†é…æ›´å¤§çš„bufferä»¥å‡å°‘Resumeæ¦‚ç‡ï¼Ÿ
   - æ˜¯å¦éœ€è¦å¼‚æ­¥å¤„ç†Resumeè¯·æ±‚ï¼Ÿ

---

## ğŸ¯ ä¸‹ä¸€æ­¥

è¯·reviewè¿™ä¸ªè®¾è®¡æ–¹æ¡ˆï¼Œç‰¹åˆ«å…³æ³¨ï¼š
1. Resumeæœºåˆ¶æ˜¯å¦ç¬¦åˆé¢„æœŸï¼Ÿ
2. æ•°æ®æµç¨‹æ˜¯å¦æ¸…æ™°ï¼Ÿ
3. æ˜¯å¦æœ‰é—æ¼çš„åœºæ™¯ï¼Ÿ
4. å®ç°ä¼˜å…ˆçº§æ˜¯å¦åˆç†ï¼Ÿ

ç¡®è®¤åæˆ‘å°†å¼€å§‹å®ç°ä»£ç ã€‚
